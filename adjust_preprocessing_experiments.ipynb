{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import sys\n",
    "import matplotlib\n",
    "from tensorflow import keras\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import support libraries\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, \\\n",
    "                                                    img_to_array, load_img\n",
    "                                                    \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, \\\n",
    "                                        BatchNormalization, GlobalAveragePooling2D\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.applications import ResNet50, InceptionV3, VGG16, Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Version check:\nPython: 3.8.2 (default, Apr 27 2020, 15:53:34) \n[GCC 9.3.0]\npandas: 1.0.3\nNumPy: 1.18.3\nsklearn: 0.22.2.post1\nmatplotlib: 3.2.1\nTensorFlow: 2.2.0\nKeras: 2.3.0-tf\n"
    }
   ],
   "source": [
    "print('Version check:')\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "print('NumPy: {}'.format(np.__version__))\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "print('TensorFlow: {}'.format(tf.__version__))\n",
    "print('Keras: {}'.format(keras.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Num GPUs Available:  1\n"
    }
   ],
   "source": [
    "# Backend Settings\n",
    "\n",
    "# clear Keras session\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# set seeds\n",
    "np.random.seed(18)\n",
    "tf.random.set_seed(18)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))\n",
    "#tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainRuntimeCallback(keras.callbacks.Callback):\n",
    "\n",
    "  def on_train_begin(self,logs={}):\n",
    "    self.start = datetime.datetime.now()\n",
    "\n",
    "  def on_train_end(self,logs={}):\n",
    "    self.process_time = (datetime.datetime.now() - self.start).total_seconds()\n",
    "\n",
    "class TestRuntimeCallback(keras.callbacks.Callback):\n",
    "\n",
    "  def on_test_begin(self,logs={}):\n",
    "    self.start = datetime.datetime.now()\n",
    "\n",
    "  def on_test_end(self,logs={}):\n",
    "    self.process_time = (datetime.datetime.now() - self.start).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, train_input, val_input, model_name):\n",
    "    data = dict()\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer = optimizer,\n",
    "                    loss = 'categorical_crossentropy',\n",
    "                    metrics = ['accuracy'])\n",
    "\n",
    "    # Create a callback to record training time\n",
    "    train_rt = TrainRuntimeCallback()\n",
    "\n",
    "    # Model fitting parameters\n",
    "    history = model.fit(\n",
    "        train_input,\n",
    "        steps_per_epoch = len(sm_train_df) // batch_size,\n",
    "        epochs = 20,\n",
    "        callbacks = [train_rt],\n",
    "        validation_data=val_input,\n",
    "        validation_steps = (len(sm_val_df) // batch_size)\n",
    "    )\n",
    "\n",
    "    train_time = train_rt.process_time\n",
    "    #print(train_time)\n",
    "\n",
    "    history_dict = history.history\n",
    "\n",
    "    data['model'] = model_name\n",
    "    data['train_time'] = train_time\n",
    "    data['train_loss'] = history_dict['loss'][-1]\n",
    "    data['train_acc'] = history_dict['accuracy'][-1]\n",
    "    data['val_loss'] = history_dict['val_loss'][-1]\n",
    "    data['val_acc'] = history_dict['val_accuracy'][-1]\n",
    "\n",
    "    return data, history_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_input):\n",
    "    \n",
    "    data = dict()\n",
    "\n",
    "    # Create test callback\n",
    "    test_rt = TestRuntimeCallback()\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(\n",
    "        test_input,\n",
    "        steps = len(sm_test_df) // batch_size,\n",
    "        callbacks = [test_rt]\n",
    "    )\n",
    "    test_time = test_rt.process_time\n",
    "    data['test_time'] = test_time\n",
    "    data['test_loss'] = test_loss\n",
    "    data['test_acc'] = test_acc\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_val(val):\n",
    "    return round(val, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_data(train_data, test_data):\n",
    "    data = dict()\n",
    "\n",
    "    data['model'] = train_data['model']\n",
    "    data['train_loss'] = round_val(train_data['train_loss'])\n",
    "    data['train_acc'] = round_val(train_data['train_acc'])\n",
    "    data['train_time'] = round_val(train_data['train_time'])\n",
    "    data['val_loss'] = round_val(train_data['val_loss'])\n",
    "    data['val_acc'] = round_val(train_data['val_acc'])\n",
    "    data['test_loss'] = round_val(test_data['test_loss'])\n",
    "    data['test_acc'] = round_val(test_data['test_acc'])\n",
    "    data['test_time'] = round_val(test_data['test_time'])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data_files/train/'\n",
    "test_dir = 'data_files/test/'\n",
    "\n",
    "train_df = pd.read_csv('data_files/train.csv')\n",
    "test_df = pd.read_csv('data_files/test.csv')\n",
    "\n",
    "train_df = train_df.sort_values('filename')\n",
    "test_df = test_df.sort_values('filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       Unnamed: 0         id_code experiment  plate well  sirna  \\\n0               0  HEPG2-01_1_B03   HEPG2-01      1  B03    513   \n36515       36515  HEPG2-01_1_B03   HEPG2-01      1  B03    513   \n1               1  HEPG2-01_1_B04   HEPG2-01      1  B04    840   \n36516       36516  HEPG2-01_1_B04   HEPG2-01      1  B04    840   \n2               2  HEPG2-01_1_B05   HEPG2-01      1  B05   1020   \n\n                     filename  \n0      HEPG2-01_1_B03_s1.jpeg  \n36515  HEPG2-01_1_B03_s2.jpeg  \n1      HEPG2-01_1_B04_s1.jpeg  \n36516  HEPG2-01_1_B04_s2.jpeg  \n2      HEPG2-01_1_B05_s1.jpeg  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id_code</th>\n      <th>experiment</th>\n      <th>plate</th>\n      <th>well</th>\n      <th>sirna</th>\n      <th>filename</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>HEPG2-01_1_B03</td>\n      <td>HEPG2-01</td>\n      <td>1</td>\n      <td>B03</td>\n      <td>513</td>\n      <td>HEPG2-01_1_B03_s1.jpeg</td>\n    </tr>\n    <tr>\n      <th>36515</th>\n      <td>36515</td>\n      <td>HEPG2-01_1_B03</td>\n      <td>HEPG2-01</td>\n      <td>1</td>\n      <td>B03</td>\n      <td>513</td>\n      <td>HEPG2-01_1_B03_s2.jpeg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>HEPG2-01_1_B04</td>\n      <td>HEPG2-01</td>\n      <td>1</td>\n      <td>B04</td>\n      <td>840</td>\n      <td>HEPG2-01_1_B04_s1.jpeg</td>\n    </tr>\n    <tr>\n      <th>36516</th>\n      <td>36516</td>\n      <td>HEPG2-01_1_B04</td>\n      <td>HEPG2-01</td>\n      <td>1</td>\n      <td>B04</td>\n      <td>840</td>\n      <td>HEPG2-01_1_B04_s2.jpeg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>HEPG2-01_1_B05</td>\n      <td>HEPG2-01</td>\n      <td>1</td>\n      <td>B05</td>\n      <td>1020</td>\n      <td>HEPG2-01_1_B05_s1.jpeg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       Unnamed: 0         well_id experiment  plate well  \\\n0               0  HEPG2-08_1_B03   HEPG2-08      1  B03   \n19897       39794  HEPG2-08_1_B03   HEPG2-08      1  B03   \n1               2  HEPG2-08_1_B04   HEPG2-08      1  B04   \n19898       39796  HEPG2-08_1_B04   HEPG2-08      1  B04   \n2               4  HEPG2-08_1_B05   HEPG2-08      1  B05   \n\n                     filename  sirna_id  \n0      HEPG2-08_1_B03_s1.jpeg       855  \n19897  HEPG2-08_1_B03_s2.jpeg       855  \n1      HEPG2-08_1_B04_s1.jpeg       710  \n19898  HEPG2-08_1_B04_s2.jpeg       710  \n2      HEPG2-08_1_B05_s1.jpeg       836  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>well_id</th>\n      <th>experiment</th>\n      <th>plate</th>\n      <th>well</th>\n      <th>filename</th>\n      <th>sirna_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>HEPG2-08_1_B03</td>\n      <td>HEPG2-08</td>\n      <td>1</td>\n      <td>B03</td>\n      <td>HEPG2-08_1_B03_s1.jpeg</td>\n      <td>855</td>\n    </tr>\n    <tr>\n      <th>19897</th>\n      <td>39794</td>\n      <td>HEPG2-08_1_B03</td>\n      <td>HEPG2-08</td>\n      <td>1</td>\n      <td>B03</td>\n      <td>HEPG2-08_1_B03_s2.jpeg</td>\n      <td>855</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>HEPG2-08_1_B04</td>\n      <td>HEPG2-08</td>\n      <td>1</td>\n      <td>B04</td>\n      <td>HEPG2-08_1_B04_s1.jpeg</td>\n      <td>710</td>\n    </tr>\n    <tr>\n      <th>19898</th>\n      <td>39796</td>\n      <td>HEPG2-08_1_B04</td>\n      <td>HEPG2-08</td>\n      <td>1</td>\n      <td>B04</td>\n      <td>HEPG2-08_1_B04_s2.jpeg</td>\n      <td>710</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>HEPG2-08_1_B05</td>\n      <td>HEPG2-08</td>\n      <td>1</td>\n      <td>B05</td>\n      <td>HEPG2-08_1_B05_s1.jpeg</td>\n      <td>836</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select only HUVEC cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[6, 10, 8, 5, 3, 1, 2, 19, 11, 7, 4, 13, 14, 17, 18, 16, 0, 9, 15, 12]\n20\n"
    }
   ],
   "source": [
    "sirna_subset = list(train_df[train_df.sirna <= 19].sirna.unique())\n",
    "print(sirna_subset)\n",
    "print(len(sirna_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_train_df = train_df[train_df.sirna.isin(sirna_subset)].copy()\n",
    "sm_test_df = test_df[test_df.sirna_id.isin(sirna_subset)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split cell types to only HUVEC\n",
    "\n",
    "sm_train_df = sm_train_df[sm_train_df.experiment.str.contains('HUVEC')]\n",
    "sm_test_df = sm_test_df[sm_test_df.experiment.str.contains('HUVEC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       Unnamed: 0         id_code experiment  plate well  sirna  \\\n7796         7796  HUVEC-01_1_D11   HUVEC-01      1  D11      1   \n44311       44311  HUVEC-01_1_D11   HUVEC-01      1  D11      1   \n7805         7805  HUVEC-01_1_D20   HUVEC-01      1  D20      3   \n44320       44320  HUVEC-01_1_D20   HUVEC-01      1  D20      3   \n7836         7836  HUVEC-01_1_F09   HUVEC-01      1  F09      5   \n44351       44351  HUVEC-01_1_F09   HUVEC-01      1  F09      5   \n7845         7845  HUVEC-01_1_F21   HUVEC-01      1  F21     10   \n44360       44360  HUVEC-01_1_F21   HUVEC-01      1  F21     10   \n7899         7899  HUVEC-01_1_I16   HUVEC-01      1  I16      8   \n44414       44414  HUVEC-01_1_I16   HUVEC-01      1  I16      8   \n\n                     filename  \n7796   HUVEC-01_1_D11_s1.jpeg  \n44311  HUVEC-01_1_D11_s2.jpeg  \n7805   HUVEC-01_1_D20_s1.jpeg  \n44320  HUVEC-01_1_D20_s2.jpeg  \n7836   HUVEC-01_1_F09_s1.jpeg  \n44351  HUVEC-01_1_F09_s2.jpeg  \n7845   HUVEC-01_1_F21_s1.jpeg  \n44360  HUVEC-01_1_F21_s2.jpeg  \n7899   HUVEC-01_1_I16_s1.jpeg  \n44414  HUVEC-01_1_I16_s2.jpeg  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id_code</th>\n      <th>experiment</th>\n      <th>plate</th>\n      <th>well</th>\n      <th>sirna</th>\n      <th>filename</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7796</th>\n      <td>7796</td>\n      <td>HUVEC-01_1_D11</td>\n      <td>HUVEC-01</td>\n      <td>1</td>\n      <td>D11</td>\n      <td>1</td>\n      <td>HUVEC-01_1_D11_s1.jpeg</td>\n    </tr>\n    <tr>\n      <th>44311</th>\n      <td>44311</td>\n      <td>HUVEC-01_1_D11</td>\n      <td>HUVEC-01</td>\n      <td>1</td>\n      <td>D11</td>\n      <td>1</td>\n      <td>HUVEC-01_1_D11_s2.jpeg</td>\n    </tr>\n    <tr>\n      <th>7805</th>\n      <td>7805</td>\n      <td>HUVEC-01_1_D20</td>\n      <td>HUVEC-01</td>\n      <td>1</td>\n      <td>D20</td>\n      <td>3</td>\n      <td>HUVEC-01_1_D20_s1.jpeg</td>\n    </tr>\n    <tr>\n      <th>44320</th>\n      <td>44320</td>\n      <td>HUVEC-01_1_D20</td>\n      <td>HUVEC-01</td>\n      <td>1</td>\n      <td>D20</td>\n      <td>3</td>\n      <td>HUVEC-01_1_D20_s2.jpeg</td>\n    </tr>\n    <tr>\n      <th>7836</th>\n      <td>7836</td>\n      <td>HUVEC-01_1_F09</td>\n      <td>HUVEC-01</td>\n      <td>1</td>\n      <td>F09</td>\n      <td>5</td>\n      <td>HUVEC-01_1_F09_s1.jpeg</td>\n    </tr>\n    <tr>\n      <th>44351</th>\n      <td>44351</td>\n      <td>HUVEC-01_1_F09</td>\n      <td>HUVEC-01</td>\n      <td>1</td>\n      <td>F09</td>\n      <td>5</td>\n      <td>HUVEC-01_1_F09_s2.jpeg</td>\n    </tr>\n    <tr>\n      <th>7845</th>\n      <td>7845</td>\n      <td>HUVEC-01_1_F21</td>\n      <td>HUVEC-01</td>\n      <td>1</td>\n      <td>F21</td>\n      <td>10</td>\n      <td>HUVEC-01_1_F21_s1.jpeg</td>\n    </tr>\n    <tr>\n      <th>44360</th>\n      <td>44360</td>\n      <td>HUVEC-01_1_F21</td>\n      <td>HUVEC-01</td>\n      <td>1</td>\n      <td>F21</td>\n      <td>10</td>\n      <td>HUVEC-01_1_F21_s2.jpeg</td>\n    </tr>\n    <tr>\n      <th>7899</th>\n      <td>7899</td>\n      <td>HUVEC-01_1_I16</td>\n      <td>HUVEC-01</td>\n      <td>1</td>\n      <td>I16</td>\n      <td>8</td>\n      <td>HUVEC-01_1_I16_s1.jpeg</td>\n    </tr>\n    <tr>\n      <th>44414</th>\n      <td>44414</td>\n      <td>HUVEC-01_1_I16</td>\n      <td>HUVEC-01</td>\n      <td>1</td>\n      <td>I16</td>\n      <td>8</td>\n      <td>HUVEC-01_1_I16_s2.jpeg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "sm_train_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       Unnamed: 0         well_id experiment  plate well  \\\n4434         8868  HUVEC-17_1_B08   HUVEC-17      1  B08   \n24331       48662  HUVEC-17_1_B08   HUVEC-17      1  B08   \n4536         9072  HUVEC-17_1_G12   HUVEC-17      1  G12   \n24433       48866  HUVEC-17_1_G12   HUVEC-17      1  G12   \n4566         9132  HUVEC-17_1_I04   HUVEC-17      1  I04   \n24463       48926  HUVEC-17_1_I04   HUVEC-17      1  I04   \n4578         9156  HUVEC-17_1_I16   HUVEC-17      1  I16   \n24475       48950  HUVEC-17_1_I16   HUVEC-17      1  I16   \n4581         9162  HUVEC-17_1_I19   HUVEC-17      1  I19   \n24478       48956  HUVEC-17_1_I19   HUVEC-17      1  I19   \n\n                     filename  sirna_id  \n4434   HUVEC-17_1_B08_s1.jpeg         3  \n24331  HUVEC-17_1_B08_s2.jpeg         3  \n4536   HUVEC-17_1_G12_s1.jpeg         1  \n24433  HUVEC-17_1_G12_s2.jpeg         1  \n4566   HUVEC-17_1_I04_s1.jpeg         6  \n24463  HUVEC-17_1_I04_s2.jpeg         6  \n4578   HUVEC-17_1_I16_s1.jpeg         8  \n24475  HUVEC-17_1_I16_s2.jpeg         8  \n4581   HUVEC-17_1_I19_s1.jpeg        10  \n24478  HUVEC-17_1_I19_s2.jpeg        10  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>well_id</th>\n      <th>experiment</th>\n      <th>plate</th>\n      <th>well</th>\n      <th>filename</th>\n      <th>sirna_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4434</th>\n      <td>8868</td>\n      <td>HUVEC-17_1_B08</td>\n      <td>HUVEC-17</td>\n      <td>1</td>\n      <td>B08</td>\n      <td>HUVEC-17_1_B08_s1.jpeg</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>24331</th>\n      <td>48662</td>\n      <td>HUVEC-17_1_B08</td>\n      <td>HUVEC-17</td>\n      <td>1</td>\n      <td>B08</td>\n      <td>HUVEC-17_1_B08_s2.jpeg</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4536</th>\n      <td>9072</td>\n      <td>HUVEC-17_1_G12</td>\n      <td>HUVEC-17</td>\n      <td>1</td>\n      <td>G12</td>\n      <td>HUVEC-17_1_G12_s1.jpeg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24433</th>\n      <td>48866</td>\n      <td>HUVEC-17_1_G12</td>\n      <td>HUVEC-17</td>\n      <td>1</td>\n      <td>G12</td>\n      <td>HUVEC-17_1_G12_s2.jpeg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4566</th>\n      <td>9132</td>\n      <td>HUVEC-17_1_I04</td>\n      <td>HUVEC-17</td>\n      <td>1</td>\n      <td>I04</td>\n      <td>HUVEC-17_1_I04_s1.jpeg</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>24463</th>\n      <td>48926</td>\n      <td>HUVEC-17_1_I04</td>\n      <td>HUVEC-17</td>\n      <td>1</td>\n      <td>I04</td>\n      <td>HUVEC-17_1_I04_s2.jpeg</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4578</th>\n      <td>9156</td>\n      <td>HUVEC-17_1_I16</td>\n      <td>HUVEC-17</td>\n      <td>1</td>\n      <td>I16</td>\n      <td>HUVEC-17_1_I16_s1.jpeg</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>24475</th>\n      <td>48950</td>\n      <td>HUVEC-17_1_I16</td>\n      <td>HUVEC-17</td>\n      <td>1</td>\n      <td>I16</td>\n      <td>HUVEC-17_1_I16_s2.jpeg</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4581</th>\n      <td>9162</td>\n      <td>HUVEC-17_1_I19</td>\n      <td>HUVEC-17</td>\n      <td>1</td>\n      <td>I19</td>\n      <td>HUVEC-17_1_I19_s1.jpeg</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>24478</th>\n      <td>48956</td>\n      <td>HUVEC-17_1_I19</td>\n      <td>HUVEC-17</td>\n      <td>1</td>\n      <td>I19</td>\n      <td>HUVEC-17_1_I19_s2.jpeg</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "sm_test_df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       Unnamed: 0         id_code experiment  plate well  sirna  \\\n7796         7796  HUVEC-01_1_D11   HUVEC-01      1  D11      1   \n44311       44311  HUVEC-01_1_D11   HUVEC-01      1  D11      1   \n44320       44320  HUVEC-01_1_D20   HUVEC-01      1  D20      3   \n7845         7845  HUVEC-01_1_F21   HUVEC-01      1  F21     10   \n7899         7899  HUVEC-01_1_I16   HUVEC-01      1  I16      8   \n\n                     filename  \n7796   HUVEC-01_1_D11_s1.jpeg  \n44311  HUVEC-01_1_D11_s2.jpeg  \n44320  HUVEC-01_1_D20_s2.jpeg  \n7845   HUVEC-01_1_F21_s1.jpeg  \n7899   HUVEC-01_1_I16_s1.jpeg  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id_code</th>\n      <th>experiment</th>\n      <th>plate</th>\n      <th>well</th>\n      <th>sirna</th>\n      <th>filename</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7796</th>\n      <td>7796</td>\n      <td>HUVEC-01_1_D11</td>\n      <td>HUVEC-01</td>\n      <td>1</td>\n      <td>D11</td>\n      <td>1</td>\n      <td>HUVEC-01_1_D11_s1.jpeg</td>\n    </tr>\n    <tr>\n      <th>44311</th>\n      <td>44311</td>\n      <td>HUVEC-01_1_D11</td>\n      <td>HUVEC-01</td>\n      <td>1</td>\n      <td>D11</td>\n      <td>1</td>\n      <td>HUVEC-01_1_D11_s2.jpeg</td>\n    </tr>\n    <tr>\n      <th>44320</th>\n      <td>44320</td>\n      <td>HUVEC-01_1_D20</td>\n      <td>HUVEC-01</td>\n      <td>1</td>\n      <td>D20</td>\n      <td>3</td>\n      <td>HUVEC-01_1_D20_s2.jpeg</td>\n    </tr>\n    <tr>\n      <th>7845</th>\n      <td>7845</td>\n      <td>HUVEC-01_1_F21</td>\n      <td>HUVEC-01</td>\n      <td>1</td>\n      <td>F21</td>\n      <td>10</td>\n      <td>HUVEC-01_1_F21_s1.jpeg</td>\n    </tr>\n    <tr>\n      <th>7899</th>\n      <td>7899</td>\n      <td>HUVEC-01_1_I16</td>\n      <td>HUVEC-01</td>\n      <td>1</td>\n      <td>I16</td>\n      <td>8</td>\n      <td>HUVEC-01_1_I16_s1.jpeg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "val_num = len(sm_train_df) * 0.2 # take 20% of training set\n",
    "\n",
    "val_df = sm_train_df.sample(int(val_num), random_state = 18)\n",
    "filename_list = list(val_df.filename)\n",
    "\n",
    "# Filter dataframes by randomly sampled rows\n",
    "# Take some from various experiments with same cell line\n",
    "# also need to shuffle sirna labels\n",
    "sm_val_df = sm_train_df[sm_train_df.filename.isin(filename_list)]\n",
    "sm_train_df = sm_train_df[~sm_train_df.filename.isin(filename_list)]\n",
    "sm_val_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "num_outputs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some rotation and adjustments to images\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    #validation_split = 0.2, # set validation set to 0.2\n",
    "    #featurewise_center= True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=90,\n",
    "    #height_shift_range=[-0.08, 0.08],\n",
    "    #width_shift_range=[-0.08,0.08],\n",
    "    #brightness_range=[0.75, 1.1]\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_train_df['sirna'] = sm_train_df.sirna.apply(lambda x: str(x))\n",
    "sm_test_df['sirna_id'] = sm_test_df.sirna_id.apply(lambda x: str(x))\n",
    "sm_val_df['sirna'] = sm_val_df.sirna.apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 512 validated image filenames belonging to 20 classes.\n"
    }
   ],
   "source": [
    "train_dir = '/home/specc/Documents/school_files/458_deep_learning/458_final_project/data_files/train/'\n",
    "\n",
    "train_generator  = train_datagen.flow_from_dataframe(\n",
    "    dataframe = sm_train_df,\n",
    "    directory = train_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    subset='training',\n",
    "    x_col='filename',\n",
    "    y_col='sirna',\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle = True,\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 128 validated image filenames belonging to 20 classes.\n"
    }
   ],
   "source": [
    "val_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe = sm_val_df,\n",
    "    directory = train_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    #subset = 'validation',\n",
    "    x_col = 'filename',\n",
    "    y_col = 'sirna',\n",
    "    class_mode = 'categorical',\n",
    "    color_mode = 'rgb',\n",
    "    shuffle = False,\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dir = 'data_files/test'\n",
    "\n",
    "# test_generator = test_datagen.flow_from_dataframe(\n",
    "#     dataframe = sm_test_df,\n",
    "#     directory = test_dir,\n",
    "#     target_size = (img_height, img_width),\n",
    "#     x_col = 'filename',\n",
    "#     y_col = 'sirna_id',\n",
    "#     color_mode = 'rgb',\n",
    "#     #class_mode = None\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 320 validated image filenames belonging to 20 classes.\n"
    }
   ],
   "source": [
    "test_dir = '/home/specc/Documents/school_files/458_deep_learning/458_final_project/data_files/test/'\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe = sm_test_df,\n",
    "    directory = test_dir,\n",
    "    target_size = (224, 224),\n",
    "    x_col='filename',\n",
    "    y_col='sirna_id',\n",
    "    mode='categorical',\n",
    "    color_mode='rgb'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store results\n",
    "results = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 layer CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 200704)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               102760960 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 102,771,668\n",
      "Trainable params: 102,771,668\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(224, 224 ,3)),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(20, activation='softmax')\n",
    "])\n",
    "\n",
    "model_name = 'CNN (1 layer)'\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "16/16 [==============================] - 11s 715ms/step - loss: 24.6550 - accuracy: 0.0508 - val_loss: 6.5363 - val_accuracy: 0.0312\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 11s 690ms/step - loss: 3.8072 - accuracy: 0.0605 - val_loss: 3.1766 - val_accuracy: 0.0781\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 11s 685ms/step - loss: 2.9534 - accuracy: 0.1074 - val_loss: 2.9987 - val_accuracy: 0.0625\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 11s 700ms/step - loss: 2.8217 - accuracy: 0.1055 - val_loss: 2.8494 - val_accuracy: 0.1250\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 11s 701ms/step - loss: 2.7164 - accuracy: 0.1309 - val_loss: 2.7503 - val_accuracy: 0.1406\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 11s 716ms/step - loss: 2.6348 - accuracy: 0.1582 - val_loss: 2.7269 - val_accuracy: 0.1250\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 11s 710ms/step - loss: 2.5742 - accuracy: 0.1777 - val_loss: 2.6348 - val_accuracy: 0.1719\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 11s 716ms/step - loss: 2.5510 - accuracy: 0.1953 - val_loss: 2.7431 - val_accuracy: 0.1484\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 11s 709ms/step - loss: 2.4563 - accuracy: 0.1895 - val_loss: 2.6415 - val_accuracy: 0.1641\n",
      "Epoch 10/15\n",
      " 8/16 [==============>...............] - ETA: 4s - loss: 2.4101 - accuracy: 0.2461"
     ]
    }
   ],
   "source": [
    "opt = 'rmsprop'\n",
    "train_data, history_dict = train_model(model, opt, train_generator, val_generator, model_name)\n",
    "test_data = test_model(model, test_generator)\n",
    "results.append(save_model_data(train_data, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 layer CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, 3, activation='relu', input_shape=(224, 224 ,3)),\n",
    "    MaxPooling2D(),\n",
    "\n",
    "    Conv2D(128, 3, activation='relu', input_shape=(224, 224 ,3)),\n",
    "    MaxPooling2D(),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(20, activation='softmax')\n",
    "])\n",
    "\n",
    "model_name = 'CNN (2 layers)'\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = 'rmsprop'\n",
    "train_data, history_dict = train_model(model, opt, train_generator, val_generator, model_name)\n",
    "test_data = test_model(model, test_generator)\n",
    "results.append(save_model_data(train_data, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_model = ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(img_height, img_width, 3)\n",
    ")\n",
    "\n",
    "res_model.trainable = False\n",
    "\n",
    "flat1 = Flatten()\n",
    "class1 = Dense(512, activation='relu')\n",
    "output = Dense(20, activation = 'softmax')\n",
    "\n",
    "model = Sequential([\n",
    "    res_model,\n",
    "    flat1,\n",
    "    class1,\n",
    "    output\n",
    "])\n",
    "\n",
    "model_name = 'ResNet50 baseline'\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = 'rmsprop'\n",
    "train_data, history_dict = train_model(model, opt, train_generator, val_generator, model_name)\n",
    "test_data = test_model(model, test_generator)\n",
    "results.append(save_model_data(train_data, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same models, accelerated learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = RMSprop(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-layer CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 109, 109, 128)     36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 54, 54, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 373248)            0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               191103488 \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 191,151,636\n",
      "Trainable params: 191,151,636\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, 3, activation='relu', input_shape=(224, 224 ,3)),\n",
    "    MaxPooling2D(),\n",
    "\n",
    "    Conv2D(128, 3, activation='relu', input_shape=(224, 224 ,3)),\n",
    "    MaxPooling2D(),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(20, activation='softmax')\n",
    "])\n",
    "\n",
    "model_name = 'CNN (2 layers) - 0.01 LR'\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "16/16 [==============================] - 27s 2s/step - loss: 1293.0549 - accuracy: 0.0391 - val_loss: 3.0302 - val_accuracy: 0.0312\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 27s 2s/step - loss: 16.7888 - accuracy: 0.0469 - val_loss: 3.0288 - val_accuracy: 0.0625\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 27s 2s/step - loss: 2.9994 - accuracy: 0.0957 - val_loss: 3.0016 - val_accuracy: 0.0703\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 27s 2s/step - loss: 2.9816 - accuracy: 0.0664 - val_loss: 2.9922 - val_accuracy: 0.0625\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 27s 2s/step - loss: 3.2393 - accuracy: 0.0781 - val_loss: 3.0223 - val_accuracy: 0.0391\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 27s 2s/step - loss: 3.0267 - accuracy: 0.0508 - val_loss: 3.0427 - val_accuracy: 0.0469\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 27s 2s/step - loss: 3.4501 - accuracy: 0.0430 - val_loss: 10.7036 - val_accuracy: 0.0469\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 27s 2s/step - loss: 14.8610 - accuracy: 0.0566 - val_loss: 3.0130 - val_accuracy: 0.0312\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 27s 2s/step - loss: 3.8181 - accuracy: 0.0566 - val_loss: 3.0163 - val_accuracy: 0.0312\n",
      "Epoch 10/15\n",
      "16/16 [==============================] - 27s 2s/step - loss: 2.9944 - accuracy: 0.0527 - val_loss: 3.0222 - val_accuracy: 0.0312\n",
      "Epoch 11/15\n",
      "16/16 [==============================] - 27s 2s/step - loss: 2.9997 - accuracy: 0.0352 - val_loss: 3.0215 - val_accuracy: 0.0312\n",
      "Epoch 12/15\n",
      "16/16 [==============================] - 27s 2s/step - loss: 3.0001 - accuracy: 0.0508 - val_loss: 3.0191 - val_accuracy: 0.0312\n",
      "Epoch 13/15\n",
      "16/16 [==============================] - 28s 2s/step - loss: 2.9954 - accuracy: 0.0527 - val_loss: 3.0244 - val_accuracy: 0.0312\n",
      "Epoch 14/15\n",
      "16/16 [==============================] - 27s 2s/step - loss: 2.9976 - accuracy: 0.0430 - val_loss: 3.0259 - val_accuracy: 0.0312\n",
      "Epoch 15/15\n",
      "16/16 [==============================] - 27s 2s/step - loss: 2.9991 - accuracy: 0.0332 - val_loss: 3.0225 - val_accuracy: 0.0312\n",
      "10/10 [==============================] - 2s 232ms/step - loss: 3.0017 - accuracy: 0.0469\n"
     ]
    }
   ],
   "source": [
    "train_data, history_dict = train_model(model, opt, train_generator, val_generator, model_name)\n",
    "test_data = test_model(model, test_generator)\n",
    "results.append(save_model_data(train_data, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               51380736  \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 74,978,708\n",
      "Trainable params: 51,390,996\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "res_model = ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(img_height, img_width, 3)\n",
    ")\n",
    "\n",
    "res_model.trainable = False\n",
    "\n",
    "flat1 = Flatten()\n",
    "class1 = Dense(512, activation='relu')\n",
    "output = Dense(20, activation = 'softmax')\n",
    "\n",
    "model = Sequential([\n",
    "    res_model,\n",
    "    flat1,\n",
    "    class1,\n",
    "    output\n",
    "])\n",
    "\n",
    "model_name = 'ResNet50 baseline - 0.01 LR'\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "16/16 [==============================] - 26s 2s/step - loss: 385.2596 - accuracy: 0.0527 - val_loss: 2.9914 - val_accuracy: 0.0391\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 25s 2s/step - loss: 6.0731 - accuracy: 0.0469 - val_loss: 2.9975 - val_accuracy: 0.0391\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 25s 2s/step - loss: 5.1115 - accuracy: 0.0586 - val_loss: 3.0025 - val_accuracy: 0.0391\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 26s 2s/step - loss: 6.0502 - accuracy: 0.0332 - val_loss: 3.0075 - val_accuracy: 0.0391\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 27s 2s/step - loss: 2.9980 - accuracy: 0.0547 - val_loss: 3.0071 - val_accuracy: 0.0391\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 26s 2s/step - loss: 5.8251 - accuracy: 0.0566 - val_loss: 3.0140 - val_accuracy: 0.0391\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 25s 2s/step - loss: 5.4945 - accuracy: 0.0488 - val_loss: 3.0213 - val_accuracy: 0.0312\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 26s 2s/step - loss: 5.6286 - accuracy: 0.0488 - val_loss: 3.0183 - val_accuracy: 0.0391\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 25s 2s/step - loss: 3.3098 - accuracy: 0.0488 - val_loss: 3.0198 - val_accuracy: 0.0312\n",
      "Epoch 10/15\n",
      "16/16 [==============================] - 25s 2s/step - loss: 2.9942 - accuracy: 0.0508 - val_loss: 3.0235 - val_accuracy: 0.0312\n",
      "Epoch 11/15\n",
      "16/16 [==============================] - 25s 2s/step - loss: 2.9980 - accuracy: 0.0332 - val_loss: 3.0218 - val_accuracy: 0.0312\n",
      "Epoch 12/15\n",
      "16/16 [==============================] - 25s 2s/step - loss: 2.9924 - accuracy: 0.0547 - val_loss: 3.0278 - val_accuracy: 0.0312\n",
      "Epoch 13/15\n",
      "16/16 [==============================] - 25s 2s/step - loss: 2.9980 - accuracy: 0.0430 - val_loss: 3.0263 - val_accuracy: 0.0312\n",
      "Epoch 14/15\n",
      "16/16 [==============================] - 25s 2s/step - loss: 2.9961 - accuracy: 0.0234 - val_loss: 3.0269 - val_accuracy: 0.0312\n",
      "Epoch 15/15\n",
      "16/16 [==============================] - 25s 2s/step - loss: 2.9946 - accuracy: 0.0488 - val_loss: 3.0288 - val_accuracy: 0.0312\n",
      "10/10 [==============================] - 10s 1s/step - loss: 2.9964 - accuracy: 0.0406\n"
     ]
    }
   ],
   "source": [
    "train_data, history_dict = train_model(model, opt, train_generator, val_generator, model_name)\n",
    "test_data = test_model(model, test_generator)\n",
    "results.append(save_model_data(train_data, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_time</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN (1 layer)</td>\n",
       "      <td>2.157</td>\n",
       "      <td>0.330</td>\n",
       "      <td>188.325</td>\n",
       "      <td>2.409</td>\n",
       "      <td>0.234</td>\n",
       "      <td>2.661</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN (2 layers)</td>\n",
       "      <td>2.068</td>\n",
       "      <td>0.332</td>\n",
       "      <td>433.127</td>\n",
       "      <td>2.318</td>\n",
       "      <td>0.180</td>\n",
       "      <td>2.643</td>\n",
       "      <td>0.209</td>\n",
       "      <td>2.593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ResNet50 baseline</td>\n",
       "      <td>2.980</td>\n",
       "      <td>0.068</td>\n",
       "      <td>401.995</td>\n",
       "      <td>3.046</td>\n",
       "      <td>0.047</td>\n",
       "      <td>2.961</td>\n",
       "      <td>0.075</td>\n",
       "      <td>11.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNN (2 layers) - 0.01 LR</td>\n",
       "      <td>2.999</td>\n",
       "      <td>0.033</td>\n",
       "      <td>434.526</td>\n",
       "      <td>3.023</td>\n",
       "      <td>0.031</td>\n",
       "      <td>3.002</td>\n",
       "      <td>0.047</td>\n",
       "      <td>2.581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ResNet50 baseline - 0.01 LR</td>\n",
       "      <td>2.995</td>\n",
       "      <td>0.049</td>\n",
       "      <td>405.245</td>\n",
       "      <td>3.029</td>\n",
       "      <td>0.031</td>\n",
       "      <td>2.996</td>\n",
       "      <td>0.041</td>\n",
       "      <td>11.192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  train_loss  train_acc  train_time  val_loss  \\\n",
       "0                CNN (1 layer)       2.157      0.330     188.325     2.409   \n",
       "1               CNN (2 layers)       2.068      0.332     433.127     2.318   \n",
       "2            ResNet50 baseline       2.980      0.068     401.995     3.046   \n",
       "3     CNN (2 layers) - 0.01 LR       2.999      0.033     434.526     3.023   \n",
       "4  ResNet50 baseline - 0.01 LR       2.995      0.049     405.245     3.029   \n",
       "\n",
       "   val_acc  test_loss  test_acc  test_time  \n",
       "0    0.234      2.661     0.181      0.996  \n",
       "1    0.180      2.643     0.209      2.593  \n",
       "2    0.047      2.961     0.075     11.249  \n",
       "3    0.031      3.002     0.047      2.581  \n",
       "4    0.031      2.996     0.041     11.192  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other base pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(include_top=False,\n",
    "                    weights = 'imagenet',\n",
    "                    input_shape=(img_height, img_width, 3),\n",
    "                    classes = num_outputs,\n",
    "                    classifier_activation='softmax')\n",
    "\n",
    "flat = Flatten()\n",
    "output = Dense(20, activation='softmax')\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    flat,\n",
    "    output\n",
    "])\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "model_name = 'InceptionV3 base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "16/16 [==============================] - 13s 810ms/step - loss: 46.9168 - accuracy: 0.0801 - val_loss: 22.5568 - val_accuracy: 0.1172\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 12s 769ms/step - loss: 17.6478 - accuracy: 0.2070 - val_loss: 12.7977 - val_accuracy: 0.1875\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 12s 775ms/step - loss: 14.3674 - accuracy: 0.2754 - val_loss: 13.9678 - val_accuracy: 0.2656\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 12s 772ms/step - loss: 15.3250 - accuracy: 0.2578 - val_loss: 12.6490 - val_accuracy: 0.2422\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 12s 772ms/step - loss: 13.4154 - accuracy: 0.3184 - val_loss: 14.8051 - val_accuracy: 0.2266\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 12s 771ms/step - loss: 13.0892 - accuracy: 0.3242 - val_loss: 22.7413 - val_accuracy: 0.1797\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 12s 771ms/step - loss: 14.2202 - accuracy: 0.3242 - val_loss: 17.0130 - val_accuracy: 0.2891\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 12s 774ms/step - loss: 12.3372 - accuracy: 0.3711 - val_loss: 17.8898 - val_accuracy: 0.2500\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 12s 774ms/step - loss: 13.3356 - accuracy: 0.3496 - val_loss: 15.9372 - val_accuracy: 0.2969\n",
      "Epoch 10/15\n",
      "16/16 [==============================] - 12s 777ms/step - loss: 9.7001 - accuracy: 0.3848 - val_loss: 19.9956 - val_accuracy: 0.1875\n",
      "Epoch 11/15\n",
      "16/16 [==============================] - 12s 776ms/step - loss: 11.7865 - accuracy: 0.3672 - val_loss: 16.7219 - val_accuracy: 0.3047\n",
      "Epoch 12/15\n",
      "16/16 [==============================] - 12s 775ms/step - loss: 9.9388 - accuracy: 0.4844 - val_loss: 13.8186 - val_accuracy: 0.2734\n",
      "Epoch 13/15\n",
      "16/16 [==============================] - 12s 773ms/step - loss: 13.1420 - accuracy: 0.3184 - val_loss: 13.9498 - val_accuracy: 0.3281\n",
      "Epoch 14/15\n",
      "16/16 [==============================] - 12s 772ms/step - loss: 9.5950 - accuracy: 0.4512 - val_loss: 15.6488 - val_accuracy: 0.3125\n",
      "Epoch 15/15\n",
      "16/16 [==============================] - 12s 771ms/step - loss: 10.0320 - accuracy: 0.4375 - val_loss: 16.7038 - val_accuracy: 0.2891\n",
      "10/10 [==============================] - 6s 568ms/step - loss: 18.8003 - accuracy: 0.2812\n"
     ]
    }
   ],
   "source": [
    "opt = 'rmsprop'\n",
    "train_data, history_dict = train_model(model, opt, train_generator, val_generator, model_name)\n",
    "test_data = test_model(model, test_generator)\n",
    "results.append(save_model_data(train_data, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Xception(include_top= False,\n",
    "                    weights = 'imagenet',\n",
    "                    input_shape = (img_height, img_width, 3),\n",
    "                    classes = num_outputs)\n",
    "\n",
    "flat = Flatten()\n",
    "output = Dense(20, activation='softmax')\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    flat,\n",
    "    output\n",
    "])\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "model_name = 'Base Xception'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "16/16 [==============================] - 24s 2s/step - loss: 30.9714 - accuracy: 0.1270 - val_loss: 10.0656 - val_accuracy: 0.2891\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 24s 1s/step - loss: 11.3663 - accuracy: 0.2754 - val_loss: 11.4937 - val_accuracy: 0.2422\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 24s 1s/step - loss: 12.4515 - accuracy: 0.2344 - val_loss: 10.4949 - val_accuracy: 0.2969\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 24s 1s/step - loss: 10.8178 - accuracy: 0.3066 - val_loss: 10.8095 - val_accuracy: 0.3359\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 24s 1s/step - loss: 9.4044 - accuracy: 0.3516 - val_loss: 8.4934 - val_accuracy: 0.3125\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 24s 1s/step - loss: 9.5483 - accuracy: 0.3652 - val_loss: 11.9689 - val_accuracy: 0.3125\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 24s 1s/step - loss: 8.2638 - accuracy: 0.4102 - val_loss: 11.5926 - val_accuracy: 0.2969\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 24s 1s/step - loss: 8.7505 - accuracy: 0.4082 - val_loss: 12.2118 - val_accuracy: 0.3438\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 24s 1s/step - loss: 8.7325 - accuracy: 0.4160 - val_loss: 9.3164 - val_accuracy: 0.3281\n",
      "Epoch 10/15\n",
      "16/16 [==============================] - 24s 1s/step - loss: 8.5135 - accuracy: 0.4492 - val_loss: 9.4045 - val_accuracy: 0.3750\n",
      "Epoch 11/15\n",
      "16/16 [==============================] - 24s 1s/step - loss: 8.3078 - accuracy: 0.4121 - val_loss: 10.6277 - val_accuracy: 0.3516\n",
      "Epoch 12/15\n",
      "16/16 [==============================] - 24s 1s/step - loss: 7.0054 - accuracy: 0.4414 - val_loss: 14.4967 - val_accuracy: 0.2188\n",
      "Epoch 13/15\n",
      "16/16 [==============================] - 24s 1s/step - loss: 7.2030 - accuracy: 0.4707 - val_loss: 11.7967 - val_accuracy: 0.3125\n",
      "Epoch 14/15\n",
      "16/16 [==============================] - 24s 2s/step - loss: 7.9071 - accuracy: 0.4668 - val_loss: 11.3191 - val_accuracy: 0.3281\n",
      "Epoch 15/15\n",
      "16/16 [==============================] - 25s 2s/step - loss: 7.5666 - accuracy: 0.4746 - val_loss: 11.6984 - val_accuracy: 0.3359\n",
      "10/10 [==============================] - 11s 1s/step - loss: 12.7364 - accuracy: 0.3063\n"
     ]
    }
   ],
   "source": [
    "opt = 'rmsprop'\n",
    "train_data, history_dict = train_model(model, opt, train_generator, val_generator, model_name)\n",
    "test_data = test_model(model, test_generator)\n",
    "results.append(save_model_data(train_data, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(img_height, img_width, 3),\n",
    "    classes=num_outputs\n",
    ")\n",
    "\n",
    "flat = Flatten()\n",
    "output = Dense(20, activation='softmax')\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    flat,\n",
    "    output\n",
    "])\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "model_name = 'Base VGG16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "16/16 [==============================] - 58s 4s/step - loss: 6.0683 - accuracy: 0.1035 - val_loss: 3.1660 - val_accuracy: 0.1484\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 58s 4s/step - loss: 2.8055 - accuracy: 0.2422 - val_loss: 2.7858 - val_accuracy: 0.2500\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 58s 4s/step - loss: 2.9316 - accuracy: 0.2695 - val_loss: 3.2001 - val_accuracy: 0.2500\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 58s 4s/step - loss: 2.5838 - accuracy: 0.3242 - val_loss: 2.9416 - val_accuracy: 0.2656\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 58s 4s/step - loss: 2.4973 - accuracy: 0.3359 - val_loss: 2.7636 - val_accuracy: 0.2891\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 58s 4s/step - loss: 2.5263 - accuracy: 0.3672 - val_loss: 3.0336 - val_accuracy: 0.2891\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 58s 4s/step - loss: 2.2890 - accuracy: 0.3945 - val_loss: 2.6136 - val_accuracy: 0.3281\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 58s 4s/step - loss: 2.1761 - accuracy: 0.3809 - val_loss: 2.3133 - val_accuracy: 0.3125\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 58s 4s/step - loss: 2.3765 - accuracy: 0.3535 - val_loss: 2.7528 - val_accuracy: 0.3125\n",
      "Epoch 10/15\n",
      "16/16 [==============================] - 58s 4s/step - loss: 2.0192 - accuracy: 0.4531 - val_loss: 2.4836 - val_accuracy: 0.3438\n",
      "Epoch 11/15\n",
      "16/16 [==============================] - 58s 4s/step - loss: 2.1556 - accuracy: 0.4102 - val_loss: 2.5766 - val_accuracy: 0.3203\n",
      "Epoch 12/15\n",
      "16/16 [==============================] - 58s 4s/step - loss: 1.9679 - accuracy: 0.4473 - val_loss: 2.8586 - val_accuracy: 0.3125\n",
      "Epoch 13/15\n",
      "16/16 [==============================] - 58s 4s/step - loss: 2.0300 - accuracy: 0.4375 - val_loss: 2.5104 - val_accuracy: 0.3203\n",
      "Epoch 14/15\n",
      "16/16 [==============================] - 58s 4s/step - loss: 1.9203 - accuracy: 0.4766 - val_loss: 2.5869 - val_accuracy: 0.3281\n",
      "Epoch 15/15\n",
      "16/16 [==============================] - 58s 4s/step - loss: 2.0035 - accuracy: 0.4766 - val_loss: 2.8190 - val_accuracy: 0.3594\n",
      "10/10 [==============================] - 27s 3s/step - loss: 2.6125 - accuracy: 0.3625\n"
     ]
    }
   ],
   "source": [
    "opt = 'rmsprop'\n",
    "train_data, history_dict = train_model(model, opt, train_generator, val_generator, model_name)\n",
    "test_data = test_model(model, test_generator)\n",
    "results.append(save_model_data(train_data, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_time</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN (1 layer)</td>\n",
       "      <td>2.157</td>\n",
       "      <td>0.330</td>\n",
       "      <td>188.325</td>\n",
       "      <td>2.409</td>\n",
       "      <td>0.234</td>\n",
       "      <td>2.661</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN (2 layers)</td>\n",
       "      <td>2.068</td>\n",
       "      <td>0.332</td>\n",
       "      <td>433.127</td>\n",
       "      <td>2.318</td>\n",
       "      <td>0.180</td>\n",
       "      <td>2.643</td>\n",
       "      <td>0.209</td>\n",
       "      <td>2.593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ResNet50 baseline</td>\n",
       "      <td>2.980</td>\n",
       "      <td>0.068</td>\n",
       "      <td>401.995</td>\n",
       "      <td>3.046</td>\n",
       "      <td>0.047</td>\n",
       "      <td>2.961</td>\n",
       "      <td>0.075</td>\n",
       "      <td>11.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNN (2 layers) - 0.01 LR</td>\n",
       "      <td>2.999</td>\n",
       "      <td>0.033</td>\n",
       "      <td>434.526</td>\n",
       "      <td>3.023</td>\n",
       "      <td>0.031</td>\n",
       "      <td>3.002</td>\n",
       "      <td>0.047</td>\n",
       "      <td>2.581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ResNet50 baseline - 0.01 LR</td>\n",
       "      <td>2.995</td>\n",
       "      <td>0.049</td>\n",
       "      <td>405.245</td>\n",
       "      <td>3.029</td>\n",
       "      <td>0.031</td>\n",
       "      <td>2.996</td>\n",
       "      <td>0.041</td>\n",
       "      <td>11.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>InceptionV3 base</td>\n",
       "      <td>10.032</td>\n",
       "      <td>0.438</td>\n",
       "      <td>198.577</td>\n",
       "      <td>16.704</td>\n",
       "      <td>0.289</td>\n",
       "      <td>18.800</td>\n",
       "      <td>0.281</td>\n",
       "      <td>6.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Base Xception</td>\n",
       "      <td>7.567</td>\n",
       "      <td>0.475</td>\n",
       "      <td>380.097</td>\n",
       "      <td>11.698</td>\n",
       "      <td>0.336</td>\n",
       "      <td>12.736</td>\n",
       "      <td>0.306</td>\n",
       "      <td>12.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Base VGG16</td>\n",
       "      <td>2.004</td>\n",
       "      <td>0.477</td>\n",
       "      <td>917.364</td>\n",
       "      <td>2.819</td>\n",
       "      <td>0.359</td>\n",
       "      <td>2.612</td>\n",
       "      <td>0.363</td>\n",
       "      <td>30.367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  train_loss  train_acc  train_time  val_loss  \\\n",
       "0                CNN (1 layer)       2.157      0.330     188.325     2.409   \n",
       "1               CNN (2 layers)       2.068      0.332     433.127     2.318   \n",
       "2            ResNet50 baseline       2.980      0.068     401.995     3.046   \n",
       "3     CNN (2 layers) - 0.01 LR       2.999      0.033     434.526     3.023   \n",
       "4  ResNet50 baseline - 0.01 LR       2.995      0.049     405.245     3.029   \n",
       "5             InceptionV3 base      10.032      0.438     198.577    16.704   \n",
       "6                Base Xception       7.567      0.475     380.097    11.698   \n",
       "7                   Base VGG16       2.004      0.477     917.364     2.819   \n",
       "\n",
       "   val_acc  test_loss  test_acc  test_time  \n",
       "0    0.234      2.661     0.181      0.996  \n",
       "1    0.180      2.643     0.209      2.593  \n",
       "2    0.047      2.961     0.075     11.249  \n",
       "3    0.031      3.002     0.047      2.581  \n",
       "4    0.031      2.996     0.041     11.192  \n",
       "5    0.289     18.800     0.281      6.340  \n",
       "6    0.336     12.736     0.306     12.422  \n",
       "7    0.359      2.612     0.363     30.367  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfreeze top 25 layers of InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(include_top=False,\n",
    "                    weights = 'imagenet',\n",
    "                    input_shape=(img_height, img_width, 3))\n",
    "\n",
    "flat = Flatten()\n",
    "output = Dense(20, activation='softmax')\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    flat,\n",
    "    output\n",
    "])\n",
    "\n",
    "model_name = 'InceptionV3 top 25 layers trainable'\n",
    "\n",
    "for layer in base_model.layers[:-24]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "16/16 [==============================] - 53s 3s/step - loss: 3.8319 - accuracy: 0.0742 - val_loss: 27531.5391 - val_accuracy: 0.0547\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 51s 3s/step - loss: 3.4821 - accuracy: 0.0547 - val_loss: 24116.1680 - val_accuracy: 0.0469\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 51s 3s/step - loss: 3.1628 - accuracy: 0.0820 - val_loss: 409.5440 - val_accuracy: 0.0391\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 50s 3s/step - loss: 3.4138 - accuracy: 0.0664 - val_loss: 22838.1035 - val_accuracy: 0.0547\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 51s 3s/step - loss: 2.9986 - accuracy: 0.0879 - val_loss: 74002.3750 - val_accuracy: 0.0391\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 51s 3s/step - loss: 3.1329 - accuracy: 0.1035 - val_loss: 150196.6250 - val_accuracy: 0.0469\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 51s 3s/step - loss: 2.8504 - accuracy: 0.1504 - val_loss: 52918.0000 - val_accuracy: 0.0391\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 50s 3s/step - loss: 2.7168 - accuracy: 0.1445 - val_loss: 18100.6953 - val_accuracy: 0.0391\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 50s 3s/step - loss: 3.0042 - accuracy: 0.1738 - val_loss: 4121.9922 - val_accuracy: 0.0625\n",
      "Epoch 10/15\n",
      "16/16 [==============================] - 50s 3s/step - loss: 2.6959 - accuracy: 0.1953 - val_loss: 6545.5166 - val_accuracy: 0.0312\n",
      "Epoch 11/15\n",
      "16/16 [==============================] - 50s 3s/step - loss: 2.4176 - accuracy: 0.2246 - val_loss: 737.1136 - val_accuracy: 0.0156\n",
      "Epoch 12/15\n",
      "16/16 [==============================] - 50s 3s/step - loss: 2.4968 - accuracy: 0.2090 - val_loss: 6869.1982 - val_accuracy: 0.0469\n",
      "Epoch 13/15\n",
      "16/16 [==============================] - 50s 3s/step - loss: 2.3826 - accuracy: 0.2617 - val_loss: 13569.3271 - val_accuracy: 0.0703\n",
      "Epoch 14/15\n",
      "16/16 [==============================] - 50s 3s/step - loss: 2.1214 - accuracy: 0.3164 - val_loss: 317.5016 - val_accuracy: 0.1016\n",
      "Epoch 15/15\n",
      "16/16 [==============================] - 49s 3s/step - loss: 2.4656 - accuracy: 0.3086 - val_loss: 172.4237 - val_accuracy: 0.0547\n",
      "10/10 [==============================] - 6s 580ms/step - loss: 132.2478 - accuracy: 0.0844\n"
     ]
    }
   ],
   "source": [
    "opt = RMSprop(learning_rate = 0.0001, momentum = 0.9)\n",
    "train_data, history_dict = train_model(model, opt, train_generator, val_generator, model_name)\n",
    "test_data = test_model(model, test_generator)\n",
    "results.append(save_model_data(train_data, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfreeze top 25 layers of Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Xception(include_top= False,\n",
    "                    weights = 'imagenet',\n",
    "                    input_shape = (img_height, img_width, 3))\n",
    "\n",
    "flat = Flatten()\n",
    "output = Dense(20, activation='softmax')\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    flat,\n",
    "    output\n",
    "])\n",
    "\n",
    "model_name = 'Xception top 25 layers trainable'\n",
    "\n",
    "for layer in base_model.layers[:-24]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "16/16 [==============================] - 90s 6s/step - loss: 3.1157 - accuracy: 0.0469 - val_loss: 2.9953 - val_accuracy: 0.0391\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 90s 6s/step - loss: 2.9957 - accuracy: 0.0527 - val_loss: 2.9968 - val_accuracy: 0.0391\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 90s 6s/step - loss: 2.9955 - accuracy: 0.0547 - val_loss: 2.9974 - val_accuracy: 0.0391\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 91s 6s/step - loss: 2.9956 - accuracy: 0.0391 - val_loss: 2.9980 - val_accuracy: 0.0391\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 90s 6s/step - loss: 2.9949 - accuracy: 0.0527 - val_loss: 2.9987 - val_accuracy: 0.0391\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 90s 6s/step - loss: 2.9954 - accuracy: 0.0410 - val_loss: 2.9993 - val_accuracy: 0.0312\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 90s 6s/step - loss: 2.9949 - accuracy: 0.0527 - val_loss: 2.9999 - val_accuracy: 0.0312\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 90s 6s/step - loss: 2.9953 - accuracy: 0.0527 - val_loss: 3.0006 - val_accuracy: 0.0312\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 90s 6s/step - loss: 2.9947 - accuracy: 0.0566 - val_loss: 3.0012 - val_accuracy: 0.0312\n",
      "Epoch 10/15\n",
      "16/16 [==============================] - 90s 6s/step - loss: 2.9943 - accuracy: 0.0586 - val_loss: 3.0016 - val_accuracy: 0.0312\n",
      "Epoch 11/15\n",
      "16/16 [==============================] - 90s 6s/step - loss: 2.9947 - accuracy: 0.0527 - val_loss: 3.0023 - val_accuracy: 0.0312\n",
      "Epoch 12/15\n",
      "16/16 [==============================] - 90s 6s/step - loss: 2.9945 - accuracy: 0.0547 - val_loss: 3.0028 - val_accuracy: 0.0312\n",
      "Epoch 13/15\n",
      "16/16 [==============================] - 90s 6s/step - loss: 2.9943 - accuracy: 0.0566 - val_loss: 3.0033 - val_accuracy: 0.0312\n",
      "Epoch 14/15\n",
      "16/16 [==============================] - 90s 6s/step - loss: 2.9945 - accuracy: 0.0410 - val_loss: 3.0038 - val_accuracy: 0.0312\n",
      "Epoch 15/15\n",
      "16/16 [==============================] - 90s 6s/step - loss: 2.9937 - accuracy: 0.0352 - val_loss: 3.0044 - val_accuracy: 0.0312\n",
      "10/10 [==============================] - 11s 1s/step - loss: 2.9946 - accuracy: 0.0500\n"
     ]
    }
   ],
   "source": [
    "opt = RMSprop(learning_rate = 0.0001, momentum = 0.9)\n",
    "train_data, history_dict = train_model(model, opt, train_generator, val_generator, model_name)\n",
    "test_data = test_model(model, test_generator)\n",
    "results.append(save_model_data(train_data, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfreeze top 25 layers of VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(img_height, img_width, 3)\n",
    ")\n",
    "\n",
    "flat = Flatten()\n",
    "output = Dense(20, activation='softmax')\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    flat,\n",
    "    output\n",
    "])\n",
    "\n",
    "#base_model.trainable = False\n",
    "\n",
    "model_name = 'VGG16 top 25 layers trainable'\n",
    "\n",
    "for layer in base_model.layers[:-24]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = RMSprop(learning_rate = 0.0001, momentum = 0.9)\n",
    "train_data, history_dict = train_model(model, opt, train_generator, val_generator, model_name)\n",
    "test_data = test_model(model, test_generator)\n",
    "results.append(save_model_data(train_data, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Global Average Pooling Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception - Global Average Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Xception(include_top= False,\n",
    "                    weights = 'imagenet',\n",
    "                    input_shape = (img_height, img_width, 3))\n",
    "\n",
    "pooling = GlobalAveragePooling2D()\n",
    "flat = Flatten()\n",
    "output = Dense(20, activation='softmax')\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    pooling,\n",
    "    flat,\n",
    "    output\n",
    "])\n",
    "\n",
    "model_name = 'Xception w GlobalAvgPooling'\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "16/16 [==============================] - 25s 2s/step - loss: 2.9749 - accuracy: 0.0859 - val_loss: 2.8702 - val_accuracy: 0.1328\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 25s 2s/step - loss: 2.5648 - accuracy: 0.2559 - val_loss: 2.5666 - val_accuracy: 0.2578\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 25s 2s/step - loss: 2.2871 - accuracy: 0.3633 - val_loss: 2.4401 - val_accuracy: 0.2734\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 25s 2s/step - loss: 2.1441 - accuracy: 0.3848 - val_loss: 2.2810 - val_accuracy: 0.3516\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 25s 2s/step - loss: 2.0054 - accuracy: 0.4316 - val_loss: 2.2461 - val_accuracy: 0.3125\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 25s 2s/step - loss: 1.8970 - accuracy: 0.4766 - val_loss: 2.1798 - val_accuracy: 0.3516\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 25s 2s/step - loss: 1.8458 - accuracy: 0.4570 - val_loss: 2.1630 - val_accuracy: 0.3594\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 25s 2s/step - loss: 1.8003 - accuracy: 0.5039 - val_loss: 2.1203 - val_accuracy: 0.3672\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 26s 2s/step - loss: 1.7291 - accuracy: 0.5215 - val_loss: 2.0703 - val_accuracy: 0.3594\n",
      "Epoch 10/15\n",
      "16/16 [==============================] - 26s 2s/step - loss: 1.6454 - accuracy: 0.5508 - val_loss: 2.0845 - val_accuracy: 0.3750\n",
      "Epoch 11/15\n",
      "16/16 [==============================] - 26s 2s/step - loss: 1.6477 - accuracy: 0.5332 - val_loss: 2.0457 - val_accuracy: 0.3828\n",
      "Epoch 12/15\n",
      "16/16 [==============================] - 25s 2s/step - loss: 1.6098 - accuracy: 0.5293 - val_loss: 2.0275 - val_accuracy: 0.3828\n",
      "Epoch 13/15\n",
      "16/16 [==============================] - 25s 2s/step - loss: 1.6212 - accuracy: 0.5176 - val_loss: 1.9964 - val_accuracy: 0.4375\n",
      "Epoch 14/15\n",
      "16/16 [==============================] - 25s 2s/step - loss: 1.5821 - accuracy: 0.5527 - val_loss: 2.0008 - val_accuracy: 0.3828\n",
      "Epoch 15/15\n",
      "16/16 [==============================] - 25s 2s/step - loss: 1.5333 - accuracy: 0.5508 - val_loss: 1.9896 - val_accuracy: 0.3984\n",
      "10/10 [==============================] - 11s 1s/step - loss: 2.0458 - accuracy: 0.3469\n"
     ]
    }
   ],
   "source": [
    "opt = RMSprop(learning_rate = 0.0001, momentum = 0.9)\n",
    "train_data, history_dict = train_model(model, opt, train_generator, val_generator, model_name)\n",
    "test_data = test_model(model, test_generator)\n",
    "results.append(save_model_data(train_data, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InceptionV3 with GlobalAvgPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(include_top=False,\n",
    "                    weights = 'imagenet',\n",
    "                    input_shape=(img_height, img_width, 3))\n",
    "\n",
    "pooling = GlobalAveragePooling2D()\n",
    "flat = Flatten()\n",
    "output = Dense(20, activation='softmax')\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    pooling,\n",
    "    flat,\n",
    "    output\n",
    "])\n",
    "\n",
    "model_name = 'InceptionV3 w GlobalAvgPooling'\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "16/16 [==============================] - 14s 869ms/step - loss: 3.1436 - accuracy: 0.0723 - val_loss: 2.9520 - val_accuracy: 0.1406\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 13s 803ms/step - loss: 2.5932 - accuracy: 0.2148 - val_loss: 2.6460 - val_accuracy: 0.2266\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 13s 803ms/step - loss: 2.2795 - accuracy: 0.3105 - val_loss: 2.6100 - val_accuracy: 0.2891\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 13s 803ms/step - loss: 2.1048 - accuracy: 0.3496 - val_loss: 2.3732 - val_accuracy: 0.3125\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 13s 786ms/step - loss: 1.9327 - accuracy: 0.4277 - val_loss: 2.2401 - val_accuracy: 0.3281\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 13s 807ms/step - loss: 1.8350 - accuracy: 0.4473 - val_loss: 2.2701 - val_accuracy: 0.3047\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 13s 825ms/step - loss: 1.7700 - accuracy: 0.4570 - val_loss: 2.1476 - val_accuracy: 0.3594\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 13s 822ms/step - loss: 1.7100 - accuracy: 0.4766 - val_loss: 2.0931 - val_accuracy: 0.4297\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 13s 810ms/step - loss: 1.6549 - accuracy: 0.4609 - val_loss: 2.2197 - val_accuracy: 0.3203\n",
      "Epoch 10/15\n",
      "16/16 [==============================] - 13s 796ms/step - loss: 1.6012 - accuracy: 0.5195 - val_loss: 2.1594 - val_accuracy: 0.4062\n",
      "Epoch 11/15\n",
      "16/16 [==============================] - 13s 803ms/step - loss: 1.5907 - accuracy: 0.5020 - val_loss: 2.0892 - val_accuracy: 0.3906\n",
      "Epoch 12/15\n",
      "16/16 [==============================] - 13s 824ms/step - loss: 1.5229 - accuracy: 0.5527 - val_loss: 2.0734 - val_accuracy: 0.3906\n",
      "Epoch 13/15\n",
      "16/16 [==============================] - 13s 807ms/step - loss: 1.5266 - accuracy: 0.5332 - val_loss: 2.1008 - val_accuracy: 0.3906\n",
      "Epoch 14/15\n",
      "16/16 [==============================] - 13s 812ms/step - loss: 1.4880 - accuracy: 0.5195 - val_loss: 2.1655 - val_accuracy: 0.3828\n",
      "Epoch 15/15\n",
      "16/16 [==============================] - 13s 794ms/step - loss: 1.4753 - accuracy: 0.5410 - val_loss: 2.1126 - val_accuracy: 0.3828\n",
      "10/10 [==============================] - 6s 581ms/step - loss: 2.1948 - accuracy: 0.3500\n"
     ]
    }
   ],
   "source": [
    "opt = RMSprop(learning_rate = 0.0001, momentum = 0.9)\n",
    "train_data, history_dict = train_model(model, opt, train_generator, val_generator, model_name)\n",
    "test_data = test_model(model, test_generator)\n",
    "results.append(save_model_data(train_data, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 with and GlobalAvgPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(img_height, img_width, 3)\n",
    ")\n",
    "\n",
    "pooling = GlobalAveragePooling2D()\n",
    "flat = Flatten()\n",
    "output = Dense(20, activation='softmax')\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    pooling,\n",
    "    flat,\n",
    "    output\n",
    "])\n",
    "\n",
    "#base_model.trainable = False\n",
    "\n",
    "model_name = 'VGG16 w GlobalAvgPooling'\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "16/16 [==============================] - 60s 4s/step - loss: 3.1330 - accuracy: 0.0547 - val_loss: 3.0117 - val_accuracy: 0.0469\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 60s 4s/step - loss: 2.9816 - accuracy: 0.0820 - val_loss: 2.9507 - val_accuracy: 0.0703\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 60s 4s/step - loss: 2.9045 - accuracy: 0.1484 - val_loss: 2.9114 - val_accuracy: 0.1094\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 60s 4s/step - loss: 2.8586 - accuracy: 0.1699 - val_loss: 2.8674 - val_accuracy: 0.1719\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 60s 4s/step - loss: 2.8063 - accuracy: 0.2383 - val_loss: 2.8363 - val_accuracy: 0.2188\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 60s 4s/step - loss: 2.7681 - accuracy: 0.2656 - val_loss: 2.7891 - val_accuracy: 0.2422\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 59s 4s/step - loss: 2.7038 - accuracy: 0.3320 - val_loss: 2.7512 - val_accuracy: 0.2578\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 59s 4s/step - loss: 2.6776 - accuracy: 0.3105 - val_loss: 2.7238 - val_accuracy: 0.3203\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 59s 4s/step - loss: 2.6226 - accuracy: 0.3574 - val_loss: 2.6860 - val_accuracy: 0.3047\n",
      "Epoch 10/15\n",
      "16/16 [==============================] - 60s 4s/step - loss: 2.5902 - accuracy: 0.3301 - val_loss: 2.6500 - val_accuracy: 0.3203\n",
      "Epoch 11/15\n",
      "16/16 [==============================] - 61s 4s/step - loss: 2.5496 - accuracy: 0.3691 - val_loss: 2.6294 - val_accuracy: 0.3047\n",
      "Epoch 12/15\n",
      "16/16 [==============================] - 61s 4s/step - loss: 2.5216 - accuracy: 0.3477 - val_loss: 2.5959 - val_accuracy: 0.3516\n",
      "Epoch 13/15\n",
      "16/16 [==============================] - 61s 4s/step - loss: 2.4950 - accuracy: 0.3965 - val_loss: 2.5720 - val_accuracy: 0.3203\n",
      "Epoch 14/15\n",
      "16/16 [==============================] - 62s 4s/step - loss: 2.4413 - accuracy: 0.4062 - val_loss: 2.5488 - val_accuracy: 0.3203\n",
      "Epoch 15/15\n",
      "16/16 [==============================] - 60s 4s/step - loss: 2.4120 - accuracy: 0.4102 - val_loss: 2.5247 - val_accuracy: 0.3047\n",
      "10/10 [==============================] - 28s 3s/step - loss: 2.4508 - accuracy: 0.3531\n"
     ]
    }
   ],
   "source": [
    "opt = RMSprop(learning_rate = 0.0001, momentum = 0.9)\n",
    "train_data, history_dict = train_model(model, opt, train_generator, val_generator, model_name)\n",
    "test_data = test_model(model, test_generator)\n",
    "results.append(save_model_data(train_data, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_time</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Xception w GlobalAvgPooling</td>\n",
       "      <td>1.533</td>\n",
       "      <td>0.551</td>\n",
       "      <td>382.221</td>\n",
       "      <td>1.990</td>\n",
       "      <td>0.398</td>\n",
       "      <td>2.046</td>\n",
       "      <td>0.347</td>\n",
       "      <td>12.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>InceptionV3 w GlobalAvgPooling</td>\n",
       "      <td>1.475</td>\n",
       "      <td>0.541</td>\n",
       "      <td>207.331</td>\n",
       "      <td>2.113</td>\n",
       "      <td>0.383</td>\n",
       "      <td>2.195</td>\n",
       "      <td>0.350</td>\n",
       "      <td>6.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VGG16 w GlobalAvgPooling</td>\n",
       "      <td>2.412</td>\n",
       "      <td>0.410</td>\n",
       "      <td>950.336</td>\n",
       "      <td>2.525</td>\n",
       "      <td>0.305</td>\n",
       "      <td>2.451</td>\n",
       "      <td>0.353</td>\n",
       "      <td>31.041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  train_loss  train_acc  train_time  \\\n",
       "0     Xception w GlobalAvgPooling       1.533      0.551     382.221   \n",
       "1  InceptionV3 w GlobalAvgPooling       1.475      0.541     207.331   \n",
       "2        VGG16 w GlobalAvgPooling       2.412      0.410     950.336   \n",
       "\n",
       "   val_loss  val_acc  test_loss  test_acc  test_time  \n",
       "0     1.990    0.398      2.046     0.347     12.842  \n",
       "1     2.113    0.383      2.195     0.350      6.458  \n",
       "2     2.525    0.305      2.451     0.353     31.041  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception with 15 trainable layers and GlobalAvgPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Xception(include_top= False,\n",
    "                    weights = 'imagenet',\n",
    "                    input_shape = (img_height, img_width, 3))\n",
    "\n",
    "pooling = GlobalAveragePooling2D()\n",
    "flat = Flatten()\n",
    "output = Dense(20, activation='softmax')\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    pooling,\n",
    "    flat,\n",
    "    output\n",
    "])\n",
    "\n",
    "model_name = 'Xception (15 trainable layers) w GlobalAvgPooling'\n",
    "\n",
    "for layer in base_model.layers[:-15]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/15\n16/16 [==============================] - 90s 6s/step - loss: 2.9401 - accuracy: 0.1016 - val_loss: 3.0204 - val_accuracy: 0.0938\nEpoch 2/15\n 4/16 [======>.......................] - ETA: 54s - loss: 2.7416 - accuracy: 0.2656"
    }
   ],
   "source": [
    "opt = RMSprop(learning_rate = 0.00001, momentum = 0.9)\n",
    "train_data, history_dict = train_model(model, opt, train_generator, val_generator, model_name)\n",
    "test_data = test_model(model, test_generator)\n",
    "results.append(save_model_data(train_data, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust datagen parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduce brightness range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some rotation and adjustments to images\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    #validation_split = 0.2, # set validation set to 0.2\n",
    "    featurewise_center= True,\n",
    "    featurewise_std_normalization=True,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=90,\n",
    "    #height_shift_range=[-0.08, 0.08],\n",
    "    #width_shift_range=[-0.08,0.08],\n",
    "    brightness_range=[0.75, 1.1]\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 512 validated image filenames belonging to 20 classes.\n"
    }
   ],
   "source": [
    "train_dir = '/home/specc/Documents/school_files/458_deep_learning/458_final_project/data_files/train/'\n",
    "\n",
    "train_generator  = train_datagen.flow_from_dataframe(\n",
    "    dataframe = sm_train_df,\n",
    "    directory = train_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    subset='training',\n",
    "    x_col='filename',\n",
    "    y_col='sirna',\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle = True,\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test best performing models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception with GlobalAvgPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Xception(include_top= False,\n",
    "                    weights = 'imagenet',\n",
    "                    input_shape = (img_height, img_width, 3))\n",
    "\n",
    "pooling = GlobalAveragePooling2D()\n",
    "flat = Flatten()\n",
    "output = Dense(20, activation='softmax')\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    pooling,\n",
    "    flat,\n",
    "    output\n",
    "])\n",
    "\n",
    "model_name = 'Xception w GlobalAvgPooling'\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n16/16 [==============================] - 26s 2s/step - loss: 2.9943 - accuracy: 0.0762 - val_loss: 2.8726 - val_accuracy: 0.1719\nEpoch 2/20\n16/16 [==============================] - 26s 2s/step - loss: 2.5643 - accuracy: 0.2500 - val_loss: 2.6019 - val_accuracy: 0.2109\nEpoch 3/20\n16/16 [==============================] - 26s 2s/step - loss: 2.3217 - accuracy: 0.3184 - val_loss: 2.4166 - val_accuracy: 0.3125\nEpoch 4/20\n16/16 [==============================] - 25s 2s/step - loss: 2.1590 - accuracy: 0.3926 - val_loss: 2.2925 - val_accuracy: 0.3125\nEpoch 5/20\n16/16 [==============================] - 26s 2s/step - loss: 2.0477 - accuracy: 0.4160 - val_loss: 2.2071 - val_accuracy: 0.3594\nEpoch 6/20\n16/16 [==============================] - 25s 2s/step - loss: 1.9416 - accuracy: 0.4355 - val_loss: 2.1749 - val_accuracy: 0.3203\nEpoch 7/20\n16/16 [==============================] - 25s 2s/step - loss: 1.8715 - accuracy: 0.4473 - val_loss: 2.1639 - val_accuracy: 0.3203\nEpoch 8/20\n16/16 [==============================] - 25s 2s/step - loss: 1.8041 - accuracy: 0.4883 - val_loss: 2.1326 - val_accuracy: 0.3516\nEpoch 9/20\n16/16 [==============================] - 25s 2s/step - loss: 1.7321 - accuracy: 0.4824 - val_loss: 2.0858 - val_accuracy: 0.3594\nEpoch 10/20\n16/16 [==============================] - 25s 2s/step - loss: 1.7255 - accuracy: 0.5000 - val_loss: 2.1043 - val_accuracy: 0.3359\nEpoch 11/20\n16/16 [==============================] - 25s 2s/step - loss: 1.6545 - accuracy: 0.5020 - val_loss: 2.0449 - val_accuracy: 0.3750\nEpoch 12/20\n16/16 [==============================] - 25s 2s/step - loss: 1.6193 - accuracy: 0.5332 - val_loss: 2.0411 - val_accuracy: 0.3750\nEpoch 13/20\n16/16 [==============================] - 25s 2s/step - loss: 1.5713 - accuracy: 0.5332 - val_loss: 2.0389 - val_accuracy: 0.3516\nEpoch 14/20\n16/16 [==============================] - 25s 2s/step - loss: 1.5605 - accuracy: 0.5371 - val_loss: 2.0348 - val_accuracy: 0.3750\nEpoch 15/20\n16/16 [==============================] - 25s 2s/step - loss: 1.5420 - accuracy: 0.5625 - val_loss: 2.0515 - val_accuracy: 0.3984\nEpoch 16/20\n16/16 [==============================] - 25s 2s/step - loss: 1.5161 - accuracy: 0.5508 - val_loss: 2.0678 - val_accuracy: 0.3750\nEpoch 17/20\n16/16 [==============================] - 25s 2s/step - loss: 1.4740 - accuracy: 0.5391 - val_loss: 2.0589 - val_accuracy: 0.4141\nEpoch 18/20\n16/16 [==============================] - 25s 2s/step - loss: 1.5168 - accuracy: 0.5430 - val_loss: 2.0208 - val_accuracy: 0.3906\nEpoch 19/20\n16/16 [==============================] - 25s 2s/step - loss: 1.4798 - accuracy: 0.5410 - val_loss: 2.0360 - val_accuracy: 0.3906\nEpoch 20/20\n16/16 [==============================] - 26s 2s/step - loss: 1.4389 - accuracy: 0.5859 - val_loss: 1.9951 - val_accuracy: 0.4062\n10/10 [==============================] - 12s 1s/step - loss: 1.9743 - accuracy: 0.3938\n"
    }
   ],
   "source": [
    "opt = RMSprop(learning_rate = 0.0001, momentum = 0.9)\n",
    "train_data, history_dict = train_model(model, opt, train_generator, val_generator, model_name)\n",
    "test_data = test_model(model, test_generator)\n",
    "results.append(save_model_data(train_data, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionV3 with GlobalAveragePooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(include_top=False,\n",
    "                    weights = 'imagenet',\n",
    "                    input_shape=(img_height, img_width, 3))\n",
    "\n",
    "pooling = GlobalAveragePooling2D()\n",
    "flat = Flatten()\n",
    "output = Dense(20, activation='softmax')\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    pooling,\n",
    "    flat,\n",
    "    output\n",
    "])\n",
    "\n",
    "model_name = 'InceptionV3 with GlobalAvgPooling'\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n16/16 [==============================] - 14s 892ms/step - loss: 3.1043 - accuracy: 0.1172 - val_loss: 2.8843 - val_accuracy: 0.1484\nEpoch 2/20\n16/16 [==============================] - 14s 852ms/step - loss: 2.5453 - accuracy: 0.2324 - val_loss: 2.5812 - val_accuracy: 0.2656\nEpoch 3/20\n16/16 [==============================] - 13s 840ms/step - loss: 2.2487 - accuracy: 0.3242 - val_loss: 2.4563 - val_accuracy: 0.2734\nEpoch 4/20\n16/16 [==============================] - 13s 841ms/step - loss: 2.0780 - accuracy: 0.3809 - val_loss: 2.3553 - val_accuracy: 0.3047\nEpoch 5/20\n16/16 [==============================] - 14s 846ms/step - loss: 1.9382 - accuracy: 0.4062 - val_loss: 2.3771 - val_accuracy: 0.3281\nEpoch 6/20\n16/16 [==============================] - 14s 853ms/step - loss: 1.8835 - accuracy: 0.4160 - val_loss: 2.2953 - val_accuracy: 0.3828\nEpoch 7/20\n16/16 [==============================] - 13s 823ms/step - loss: 1.7581 - accuracy: 0.4824 - val_loss: 2.1451 - val_accuracy: 0.3359\nEpoch 8/20\n16/16 [==============================] - 13s 812ms/step - loss: 1.7905 - accuracy: 0.4082 - val_loss: 2.1697 - val_accuracy: 0.3203\nEpoch 9/20\n16/16 [==============================] - 13s 814ms/step - loss: 1.6418 - accuracy: 0.4980 - val_loss: 2.1516 - val_accuracy: 0.3516\nEpoch 10/20\n16/16 [==============================] - 13s 812ms/step - loss: 1.6799 - accuracy: 0.4824 - val_loss: 2.1111 - val_accuracy: 0.4219\nEpoch 11/20\n16/16 [==============================] - 13s 816ms/step - loss: 1.5932 - accuracy: 0.5117 - val_loss: 2.0670 - val_accuracy: 0.4219\nEpoch 12/20\n16/16 [==============================] - 13s 817ms/step - loss: 1.5261 - accuracy: 0.5234 - val_loss: 2.2257 - val_accuracy: 0.3672\nEpoch 13/20\n16/16 [==============================] - 13s 811ms/step - loss: 1.6107 - accuracy: 0.5195 - val_loss: 2.0931 - val_accuracy: 0.4141\nEpoch 14/20\n16/16 [==============================] - 13s 820ms/step - loss: 1.4816 - accuracy: 0.5371 - val_loss: 2.0846 - val_accuracy: 0.4141\nEpoch 15/20\n16/16 [==============================] - 13s 818ms/step - loss: 1.5192 - accuracy: 0.4922 - val_loss: 2.0804 - val_accuracy: 0.3828\nEpoch 16/20\n16/16 [==============================] - 13s 818ms/step - loss: 1.4586 - accuracy: 0.5547 - val_loss: 1.9987 - val_accuracy: 0.4531\nEpoch 17/20\n16/16 [==============================] - 13s 813ms/step - loss: 1.3908 - accuracy: 0.5742 - val_loss: 2.0543 - val_accuracy: 0.4141\nEpoch 18/20\n16/16 [==============================] - 13s 821ms/step - loss: 1.4024 - accuracy: 0.5645 - val_loss: 2.0261 - val_accuracy: 0.4297\nEpoch 19/20\n16/16 [==============================] - 13s 817ms/step - loss: 1.3985 - accuracy: 0.5645 - val_loss: 2.1318 - val_accuracy: 0.3984\nEpoch 20/20\n16/16 [==============================] - 13s 824ms/step - loss: 1.3652 - accuracy: 0.5566 - val_loss: 2.0725 - val_accuracy: 0.4297\n10/10 [==============================] - 6s 612ms/step - loss: 2.2242 - accuracy: 0.3781\n"
    }
   ],
   "source": [
    "opt = RMSprop(learning_rate = 0.0001, momentum = 0.9)\n",
    "train_data, history_dict = train_model(model, opt, train_generator, val_generator, model_name)\n",
    "test_data = test_model(model, test_generator)\n",
    "results.append(save_model_data(train_data, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                               model  train_loss  train_acc  train_time  \\\n0        Xception w GlobalAvgPooling       1.439      0.586     536.047   \n1  InceptionV3 with GlobalAvgPooling       1.365      0.557     281.862   \n\n   val_loss  val_acc  test_loss  test_acc  test_time  \n0     1.995    0.406      1.974     0.394     13.104  \n1     2.073    0.430      2.224     0.378      6.828  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>train_loss</th>\n      <th>train_acc</th>\n      <th>train_time</th>\n      <th>val_loss</th>\n      <th>val_acc</th>\n      <th>test_loss</th>\n      <th>test_acc</th>\n      <th>test_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Xception w GlobalAvgPooling</td>\n      <td>1.439</td>\n      <td>0.586</td>\n      <td>536.047</td>\n      <td>1.995</td>\n      <td>0.406</td>\n      <td>1.974</td>\n      <td>0.394</td>\n      <td>13.104</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>InceptionV3 with GlobalAvgPooling</td>\n      <td>1.365</td>\n      <td>0.557</td>\n      <td>281.862</td>\n      <td>2.073</td>\n      <td>0.430</td>\n      <td>2.224</td>\n      <td>0.378</td>\n      <td>6.828</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduce height shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 512 validated image filenames belonging to 20 classes.\n"
    }
   ],
   "source": [
    "# Add some rotation and adjustments to images\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    #validation_split = 0.2, # set validation set to 0.2\n",
    "    #featurewise_center= True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=90,\n",
    "    height_shift_range=[-0.08, 0.08],\n",
    "    #width_shift_range=[-0.08,0.08],\n",
    "    #brightness_range=[0.75, 1.1]\n",
    ")\n",
    "\n",
    "train_generator  = train_datagen.flow_from_dataframe(\n",
    "    dataframe = sm_train_df,\n",
    "    directory = train_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    subset='training',\n",
    "    x_col='filename',\n",
    "    y_col='sirna',\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle = True,\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test best models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception with GlobalAvgPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Xception(include_top= False,\n",
    "                    weights = 'imagenet',\n",
    "                    input_shape = (img_height, img_width, 3))\n",
    "\n",
    "pooling = GlobalAveragePooling2D()\n",
    "flat = Flatten()\n",
    "output = Dense(20, activation='softmax')\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    pooling,\n",
    "    flat,\n",
    "    output\n",
    "])\n",
    "\n",
    "model_name = 'Xception w GlobalAvgPooling'\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n16/16 [==============================] - 25s 2s/step - loss: 2.9768 - accuracy: 0.0996 - val_loss: 2.8663 - val_accuracy: 0.1719\nEpoch 2/20\n16/16 [==============================] - 25s 2s/step - loss: 2.5767 - accuracy: 0.2676 - val_loss: 2.6662 - val_accuracy: 0.2266\nEpoch 3/20\n16/16 [==============================] - 25s 2s/step - loss: 2.3595 - accuracy: 0.3438 - val_loss: 2.4927 - val_accuracy: 0.2422\nEpoch 4/20\n16/16 [==============================] - 25s 2s/step - loss: 2.1633 - accuracy: 0.3887 - val_loss: 2.4583 - val_accuracy: 0.2422\nEpoch 5/20\n16/16 [==============================] - 24s 2s/step - loss: 2.1201 - accuracy: 0.3496 - val_loss: 2.3378 - val_accuracy: 0.2500\nEpoch 6/20\n16/16 [==============================] - 25s 2s/step - loss: 1.9709 - accuracy: 0.4219 - val_loss: 2.2793 - val_accuracy: 0.2891\nEpoch 7/20\n16/16 [==============================] - 25s 2s/step - loss: 1.9162 - accuracy: 0.4609 - val_loss: 2.2433 - val_accuracy: 0.3125\nEpoch 8/20\n16/16 [==============================] - 25s 2s/step - loss: 1.8619 - accuracy: 0.4551 - val_loss: 2.2203 - val_accuracy: 0.3047\nEpoch 9/20\n16/16 [==============================] - 25s 2s/step - loss: 1.7764 - accuracy: 0.4863 - val_loss: 2.1675 - val_accuracy: 0.3438\nEpoch 10/20\n16/16 [==============================] - 25s 2s/step - loss: 1.7950 - accuracy: 0.4688 - val_loss: 2.1789 - val_accuracy: 0.3281\nEpoch 11/20\n16/16 [==============================] - 25s 2s/step - loss: 1.7039 - accuracy: 0.4766 - val_loss: 2.1336 - val_accuracy: 0.3750\nEpoch 12/20\n16/16 [==============================] - 25s 2s/step - loss: 1.6949 - accuracy: 0.4922 - val_loss: 2.1552 - val_accuracy: 0.3594\nEpoch 13/20\n16/16 [==============================] - 25s 2s/step - loss: 1.6532 - accuracy: 0.5098 - val_loss: 2.1085 - val_accuracy: 0.3906\nEpoch 14/20\n16/16 [==============================] - 25s 2s/step - loss: 1.6558 - accuracy: 0.5098 - val_loss: 2.1640 - val_accuracy: 0.3828\nEpoch 15/20\n16/16 [==============================] - 25s 2s/step - loss: 1.6183 - accuracy: 0.5039 - val_loss: 2.0693 - val_accuracy: 0.4141\nEpoch 16/20\n16/16 [==============================] - 26s 2s/step - loss: 1.5909 - accuracy: 0.5176 - val_loss: 2.0614 - val_accuracy: 0.4062\nEpoch 17/20\n16/16 [==============================] - 25s 2s/step - loss: 1.5614 - accuracy: 0.5371 - val_loss: 2.0434 - val_accuracy: 0.3750\nEpoch 18/20\n16/16 [==============================] - 25s 2s/step - loss: 1.5796 - accuracy: 0.5293 - val_loss: 2.0634 - val_accuracy: 0.4062\nEpoch 19/20\n16/16 [==============================] - 26s 2s/step - loss: 1.5146 - accuracy: 0.5508 - val_loss: 2.0658 - val_accuracy: 0.4062\nEpoch 20/20\n16/16 [==============================] - 25s 2s/step - loss: 1.5264 - accuracy: 0.5684 - val_loss: 2.1439 - val_accuracy: 0.3906\n10/10 [==============================] - 12s 1s/step - loss: 2.1018 - accuracy: 0.3469\n"
    }
   ],
   "source": [
    "opt = RMSprop(learning_rate = 0.0001, momentum = 0.9)\n",
    "train_data, history_dict = train_model(model, opt, train_generator, val_generator, model_name)\n",
    "test_data = test_model(model, test_generator)\n",
    "results.append(save_model_data(train_data, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                               model  train_loss  train_acc  train_time  \\\n0        Xception w GlobalAvgPooling       1.439      0.586     536.047   \n1  InceptionV3 with GlobalAvgPooling       1.365      0.557     281.862   \n2        Xception w GlobalAvgPooling       1.526      0.568     527.488   \n\n   val_loss  val_acc  test_loss  test_acc  test_time  \n0     1.995    0.406      1.974     0.394     13.104  \n1     2.073    0.430      2.224     0.378      6.828  \n2     2.144    0.391      2.102     0.347     13.210  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>train_loss</th>\n      <th>train_acc</th>\n      <th>train_time</th>\n      <th>val_loss</th>\n      <th>val_acc</th>\n      <th>test_loss</th>\n      <th>test_acc</th>\n      <th>test_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Xception w GlobalAvgPooling</td>\n      <td>1.439</td>\n      <td>0.586</td>\n      <td>536.047</td>\n      <td>1.995</td>\n      <td>0.406</td>\n      <td>1.974</td>\n      <td>0.394</td>\n      <td>13.104</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>InceptionV3 with GlobalAvgPooling</td>\n      <td>1.365</td>\n      <td>0.557</td>\n      <td>281.862</td>\n      <td>2.073</td>\n      <td>0.430</td>\n      <td>2.224</td>\n      <td>0.378</td>\n      <td>6.828</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Xception w GlobalAvgPooling</td>\n      <td>1.526</td>\n      <td>0.568</td>\n      <td>527.488</td>\n      <td>2.144</td>\n      <td>0.391</td>\n      <td>2.102</td>\n      <td>0.347</td>\n      <td>13.210</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(include_top=False,\n",
    "                    weights = 'imagenet',\n",
    "                    input_shape=(img_height, img_width, 3))\n",
    "\n",
    "pooling = GlobalAveragePooling2D()\n",
    "flat = Flatten()\n",
    "output = Dense(20, activation='softmax')\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    pooling,\n",
    "    flat,\n",
    "    output\n",
    "])\n",
    "\n",
    "model_name = 'InceptionV3 trainable with GlobalAvgPooling'\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n16/16 [==============================] - 14s 865ms/step - loss: 3.0695 - accuracy: 0.0898 - val_loss: 3.1039 - val_accuracy: 0.1094\nEpoch 2/20\n16/16 [==============================] - 13s 828ms/step - loss: 2.5344 - accuracy: 0.2559 - val_loss: 2.7587 - val_accuracy: 0.2344\nEpoch 3/20\n16/16 [==============================] - 13s 816ms/step - loss: 2.2888 - accuracy: 0.3145 - val_loss: 2.5208 - val_accuracy: 0.2578\nEpoch 4/20\n16/16 [==============================] - 13s 811ms/step - loss: 2.1106 - accuracy: 0.3633 - val_loss: 2.5958 - val_accuracy: 0.2578\nEpoch 5/20\n16/16 [==============================] - 13s 837ms/step - loss: 2.0261 - accuracy: 0.3418 - val_loss: 2.3443 - val_accuracy: 0.3203\nEpoch 6/20\n16/16 [==============================] - 13s 825ms/step - loss: 1.8916 - accuracy: 0.4141 - val_loss: 2.3462 - val_accuracy: 0.2969\nEpoch 7/20\n16/16 [==============================] - 13s 823ms/step - loss: 1.8147 - accuracy: 0.4531 - val_loss: 2.3957 - val_accuracy: 0.3047\nEpoch 8/20\n16/16 [==============================] - 13s 822ms/step - loss: 1.7631 - accuracy: 0.4648 - val_loss: 2.3239 - val_accuracy: 0.3438\nEpoch 9/20\n16/16 [==============================] - 13s 812ms/step - loss: 1.7905 - accuracy: 0.4297 - val_loss: 2.1821 - val_accuracy: 0.3672\nEpoch 10/20\n16/16 [==============================] - 13s 821ms/step - loss: 1.6528 - accuracy: 0.4941 - val_loss: 2.2676 - val_accuracy: 0.3594\nEpoch 11/20\n16/16 [==============================] - 13s 838ms/step - loss: 1.5916 - accuracy: 0.5039 - val_loss: 2.2910 - val_accuracy: 0.3672\nEpoch 12/20\n16/16 [==============================] - 13s 823ms/step - loss: 1.6260 - accuracy: 0.5117 - val_loss: 2.3145 - val_accuracy: 0.3359\nEpoch 13/20\n16/16 [==============================] - 13s 813ms/step - loss: 1.6228 - accuracy: 0.4980 - val_loss: 2.2142 - val_accuracy: 0.3750\nEpoch 14/20\n16/16 [==============================] - 14s 848ms/step - loss: 1.5162 - accuracy: 0.5410 - val_loss: 2.0982 - val_accuracy: 0.3906\nEpoch 15/20\n16/16 [==============================] - 13s 827ms/step - loss: 1.4816 - accuracy: 0.5430 - val_loss: 2.2902 - val_accuracy: 0.3516\nEpoch 16/20\n16/16 [==============================] - 13s 818ms/step - loss: 1.5263 - accuracy: 0.5000 - val_loss: 2.1768 - val_accuracy: 0.4062\nEpoch 17/20\n16/16 [==============================] - 13s 827ms/step - loss: 1.5369 - accuracy: 0.5195 - val_loss: 2.0900 - val_accuracy: 0.4219\nEpoch 18/20\n16/16 [==============================] - 13s 815ms/step - loss: 1.5180 - accuracy: 0.5234 - val_loss: 2.1688 - val_accuracy: 0.3828\nEpoch 19/20\n16/16 [==============================] - 13s 810ms/step - loss: 1.4087 - accuracy: 0.5645 - val_loss: 2.1122 - val_accuracy: 0.3984\nEpoch 20/20\n16/16 [==============================] - 13s 832ms/step - loss: 1.4042 - accuracy: 0.5664 - val_loss: 2.1230 - val_accuracy: 0.4062\n10/10 [==============================] - 6s 592ms/step - loss: 2.1768 - accuracy: 0.3688\n"
    }
   ],
   "source": [
    "opt = RMSprop(learning_rate = 0.0001, momentum = 0.9)\n",
    "train_data, history_dict = train_model(model, opt, train_generator, val_generator, model_name)\n",
    "test_data = test_model(model, test_generator)\n",
    "results.append(save_model_data(train_data, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduce width shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 512 validated image filenames belonging to 20 classes.\n"
    }
   ],
   "source": [
    "# Add some rotation and adjustments to images\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    #validation_split = 0.2, # set validation set to 0.2\n",
    "    #featurewise_center= True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=90,\n",
    "    #height_shift_range=[-0.08, 0.08],\n",
    "    width_shift_range=[-0.08,0.08],\n",
    "    #brightness_range=[0.75, 1.1]\n",
    ")\n",
    "\n",
    "train_generator  = train_datagen.flow_from_dataframe(\n",
    "    dataframe = sm_train_df,\n",
    "    directory = train_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    subset='training',\n",
    "    x_col='filename',\n",
    "    y_col='sirna',\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle = True,\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception and GlobalAvgPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Xception(include_top= False,\n",
    "                    weights = 'imagenet',\n",
    "                    input_shape = (img_height, img_width, 3))\n",
    "\n",
    "pooling = GlobalAveragePooling2D()\n",
    "flat = Flatten()\n",
    "output = Dense(20, activation='softmax')\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    pooling,\n",
    "    flat,\n",
    "    output\n",
    "])\n",
    "\n",
    "model_name = 'Xception w GlobalAvgPooling & width shift'\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n16/16 [==============================] - 26s 2s/step - loss: 3.0270 - accuracy: 0.0820 - val_loss: 2.8359 - val_accuracy: 0.1562\nEpoch 2/20\n16/16 [==============================] - 26s 2s/step - loss: 2.5818 - accuracy: 0.2539 - val_loss: 2.6537 - val_accuracy: 0.2188\nEpoch 3/20\n16/16 [==============================] - 25s 2s/step - loss: 2.3102 - accuracy: 0.3652 - val_loss: 2.4908 - val_accuracy: 0.2344\nEpoch 4/20\n16/16 [==============================] - 26s 2s/step - loss: 2.1379 - accuracy: 0.3867 - val_loss: 2.3741 - val_accuracy: 0.3047\nEpoch 5/20\n16/16 [==============================] - 25s 2s/step - loss: 2.0268 - accuracy: 0.4023 - val_loss: 2.3318 - val_accuracy: 0.2734\nEpoch 6/20\n16/16 [==============================] - 25s 2s/step - loss: 1.9482 - accuracy: 0.4297 - val_loss: 2.2711 - val_accuracy: 0.3125\nEpoch 7/20\n16/16 [==============================] - 25s 2s/step - loss: 1.8513 - accuracy: 0.4688 - val_loss: 2.2031 - val_accuracy: 0.3281\nEpoch 8/20\n16/16 [==============================] - 25s 2s/step - loss: 1.8484 - accuracy: 0.4668 - val_loss: 2.1838 - val_accuracy: 0.3359\nEpoch 9/20\n16/16 [==============================] - 25s 2s/step - loss: 1.7838 - accuracy: 0.4688 - val_loss: 2.1780 - val_accuracy: 0.3672\nEpoch 10/20\n16/16 [==============================] - 25s 2s/step - loss: 1.7437 - accuracy: 0.4883 - val_loss: 2.1025 - val_accuracy: 0.3672\nEpoch 11/20\n16/16 [==============================] - 25s 2s/step - loss: 1.6940 - accuracy: 0.5020 - val_loss: 2.0667 - val_accuracy: 0.3672\nEpoch 12/20\n16/16 [==============================] - 26s 2s/step - loss: 1.6989 - accuracy: 0.4746 - val_loss: 2.0774 - val_accuracy: 0.3672\nEpoch 13/20\n16/16 [==============================] - 25s 2s/step - loss: 1.6537 - accuracy: 0.5059 - val_loss: 2.0511 - val_accuracy: 0.3750\nEpoch 14/20\n16/16 [==============================] - 26s 2s/step - loss: 1.6102 - accuracy: 0.5156 - val_loss: 2.0562 - val_accuracy: 0.3672\nEpoch 15/20\n16/16 [==============================] - 26s 2s/step - loss: 1.5546 - accuracy: 0.5449 - val_loss: 2.0678 - val_accuracy: 0.3750\nEpoch 16/20\n16/16 [==============================] - 25s 2s/step - loss: 1.5735 - accuracy: 0.5234 - val_loss: 2.0720 - val_accuracy: 0.3672\nEpoch 17/20\n16/16 [==============================] - 25s 2s/step - loss: 1.5597 - accuracy: 0.5547 - val_loss: 2.0432 - val_accuracy: 0.3906\nEpoch 18/20\n16/16 [==============================] - 26s 2s/step - loss: 1.5383 - accuracy: 0.5312 - val_loss: 2.0663 - val_accuracy: 0.3828\nEpoch 19/20\n16/16 [==============================] - 26s 2s/step - loss: 1.4355 - accuracy: 0.5820 - val_loss: 2.0387 - val_accuracy: 0.3828\nEpoch 20/20\n16/16 [==============================] - 25s 2s/step - loss: 1.4896 - accuracy: 0.5488 - val_loss: 2.0642 - val_accuracy: 0.3672\n10/10 [==============================] - 12s 1s/step - loss: 2.0455 - accuracy: 0.4031\n"
    }
   ],
   "source": [
    "opt = RMSprop(learning_rate = 0.0001, momentum = 0.9)\n",
    "train_data, history_dict = train_model(model, opt, train_generator, val_generator, model_name)\n",
    "test_data = test_model(model, test_generator)\n",
    "results.append(save_model_data(train_data, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('xception.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionV3 with GlobalAvgPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(include_top=False,\n",
    "                    weights = 'imagenet',\n",
    "                    input_shape=(img_height, img_width, 3))\n",
    "\n",
    "pooling = GlobalAveragePooling2D()\n",
    "flat = Flatten()\n",
    "output = Dense(20, activation='softmax')\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    pooling,\n",
    "    flat,\n",
    "    output\n",
    "])\n",
    "\n",
    "model_name = 'InceptionV3 w GlobalAvgPooling & width shift'\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n16/16 [==============================] - 14s 877ms/step - loss: 3.1333 - accuracy: 0.0566 - val_loss: 2.9689 - val_accuracy: 0.1094\nEpoch 2/20\n16/16 [==============================] - 13s 839ms/step - loss: 2.5945 - accuracy: 0.2363 - val_loss: 2.6943 - val_accuracy: 0.1719\nEpoch 3/20\n16/16 [==============================] - 13s 837ms/step - loss: 2.2930 - accuracy: 0.2988 - val_loss: 2.6552 - val_accuracy: 0.2344\nEpoch 4/20\n16/16 [==============================] - 13s 823ms/step - loss: 2.0367 - accuracy: 0.3691 - val_loss: 2.4463 - val_accuracy: 0.2422\nEpoch 5/20\n16/16 [==============================] - 14s 849ms/step - loss: 1.9627 - accuracy: 0.3848 - val_loss: 2.4213 - val_accuracy: 0.3281\nEpoch 6/20\n16/16 [==============================] - 13s 842ms/step - loss: 1.9073 - accuracy: 0.4102 - val_loss: 2.3774 - val_accuracy: 0.3203\nEpoch 7/20\n16/16 [==============================] - 13s 837ms/step - loss: 1.8393 - accuracy: 0.4473 - val_loss: 2.4452 - val_accuracy: 0.2812\nEpoch 8/20\n16/16 [==============================] - 13s 842ms/step - loss: 1.8204 - accuracy: 0.4199 - val_loss: 2.2560 - val_accuracy: 0.3516\nEpoch 9/20\n16/16 [==============================] - 13s 825ms/step - loss: 1.7296 - accuracy: 0.4902 - val_loss: 2.2560 - val_accuracy: 0.3438\nEpoch 10/20\n16/16 [==============================] - 13s 809ms/step - loss: 1.6387 - accuracy: 0.4805 - val_loss: 2.2533 - val_accuracy: 0.3516\nEpoch 11/20\n16/16 [==============================] - 13s 807ms/step - loss: 1.6529 - accuracy: 0.4766 - val_loss: 2.3252 - val_accuracy: 0.3281\nEpoch 12/20\n16/16 [==============================] - 13s 806ms/step - loss: 1.5847 - accuracy: 0.5312 - val_loss: 2.1487 - val_accuracy: 0.3594\nEpoch 13/20\n16/16 [==============================] - 13s 804ms/step - loss: 1.5490 - accuracy: 0.5078 - val_loss: 2.0710 - val_accuracy: 0.3984\nEpoch 14/20\n16/16 [==============================] - 13s 806ms/step - loss: 1.5952 - accuracy: 0.5059 - val_loss: 2.0241 - val_accuracy: 0.4219\nEpoch 15/20\n16/16 [==============================] - 13s 810ms/step - loss: 1.4499 - accuracy: 0.5332 - val_loss: 2.1905 - val_accuracy: 0.3750\nEpoch 16/20\n16/16 [==============================] - 13s 829ms/step - loss: 1.4758 - accuracy: 0.5527 - val_loss: 2.1063 - val_accuracy: 0.3672\nEpoch 17/20\n16/16 [==============================] - 13s 837ms/step - loss: 1.4390 - accuracy: 0.5488 - val_loss: 1.9935 - val_accuracy: 0.4375\nEpoch 18/20\n16/16 [==============================] - 13s 823ms/step - loss: 1.4140 - accuracy: 0.5527 - val_loss: 2.1070 - val_accuracy: 0.3828\nEpoch 19/20\n16/16 [==============================] - 13s 829ms/step - loss: 1.3716 - accuracy: 0.5566 - val_loss: 2.0297 - val_accuracy: 0.4297\nEpoch 20/20\n16/16 [==============================] - 13s 840ms/step - loss: 1.4259 - accuracy: 0.5508 - val_loss: 2.1841 - val_accuracy: 0.3984\n10/10 [==============================] - 6s 625ms/step - loss: 2.1456 - accuracy: 0.3781\n"
    }
   ],
   "source": [
    "opt = RMSprop(learning_rate = 0.0001, momentum = 0.9)\n",
    "train_data, history_dict = train_model(model, opt, train_generator, val_generator, model_name)\n",
    "test_data = test_model(model, test_generator)\n",
    "results.append(save_model_data(train_data, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('inception.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                            model  train_loss  train_acc  \\\n0                     Xception w GlobalAvgPooling       1.439      0.586   \n1               InceptionV3 with GlobalAvgPooling       1.365      0.557   \n2                     Xception w GlobalAvgPooling       1.526      0.568   \n3     InceptionV3 trainable with GlobalAvgPooling       1.404      0.566   \n4       Xception w GlobalAvgPooling & width shift       1.484      0.557   \n5    InceptionV3 w GlobalAvgPooling & width shift       1.366      0.562   \n6    InceptionV3 w GlobalAvgPooling & width shift       1.278      0.605   \n7  Xception w GlobalAvgPooling & brightness shift       1.382      0.605   \n8       Xception w GlobalAvgPooling & width shift       1.490      0.549   \n9    InceptionV3 w GlobalAvgPooling & width shift       1.426      0.551   \n\n   train_time  val_loss  val_acc  test_loss  test_acc  test_time  \n0     536.047     1.995    0.406      1.974     0.394     13.104  \n1     281.862     2.073    0.430      2.224     0.378      6.828  \n2     527.488     2.144    0.391      2.102     0.347     13.210  \n3     280.952     2.123    0.406      2.177     0.369      6.589  \n4     525.483     1.982    0.406      2.035     0.397     13.099  \n5     280.240     2.035    0.422      2.099     0.409      6.617  \n6     277.146     2.159    0.422      2.179     0.369      6.578  \n7     517.894     1.916    0.422      2.017     0.384     12.895  \n8     534.560     2.064    0.367      2.045     0.403     12.887  \n9     281.818     2.184    0.398      2.146     0.378      6.976  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>train_loss</th>\n      <th>train_acc</th>\n      <th>train_time</th>\n      <th>val_loss</th>\n      <th>val_acc</th>\n      <th>test_loss</th>\n      <th>test_acc</th>\n      <th>test_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Xception w GlobalAvgPooling</td>\n      <td>1.439</td>\n      <td>0.586</td>\n      <td>536.047</td>\n      <td>1.995</td>\n      <td>0.406</td>\n      <td>1.974</td>\n      <td>0.394</td>\n      <td>13.104</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>InceptionV3 with GlobalAvgPooling</td>\n      <td>1.365</td>\n      <td>0.557</td>\n      <td>281.862</td>\n      <td>2.073</td>\n      <td>0.430</td>\n      <td>2.224</td>\n      <td>0.378</td>\n      <td>6.828</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Xception w GlobalAvgPooling</td>\n      <td>1.526</td>\n      <td>0.568</td>\n      <td>527.488</td>\n      <td>2.144</td>\n      <td>0.391</td>\n      <td>2.102</td>\n      <td>0.347</td>\n      <td>13.210</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>InceptionV3 trainable with GlobalAvgPooling</td>\n      <td>1.404</td>\n      <td>0.566</td>\n      <td>280.952</td>\n      <td>2.123</td>\n      <td>0.406</td>\n      <td>2.177</td>\n      <td>0.369</td>\n      <td>6.589</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Xception w GlobalAvgPooling &amp; width shift</td>\n      <td>1.484</td>\n      <td>0.557</td>\n      <td>525.483</td>\n      <td>1.982</td>\n      <td>0.406</td>\n      <td>2.035</td>\n      <td>0.397</td>\n      <td>13.099</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>InceptionV3 w GlobalAvgPooling &amp; width shift</td>\n      <td>1.366</td>\n      <td>0.562</td>\n      <td>280.240</td>\n      <td>2.035</td>\n      <td>0.422</td>\n      <td>2.099</td>\n      <td>0.409</td>\n      <td>6.617</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>InceptionV3 w GlobalAvgPooling &amp; width shift</td>\n      <td>1.278</td>\n      <td>0.605</td>\n      <td>277.146</td>\n      <td>2.159</td>\n      <td>0.422</td>\n      <td>2.179</td>\n      <td>0.369</td>\n      <td>6.578</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Xception w GlobalAvgPooling &amp; brightness shift</td>\n      <td>1.382</td>\n      <td>0.605</td>\n      <td>517.894</td>\n      <td>1.916</td>\n      <td>0.422</td>\n      <td>2.017</td>\n      <td>0.384</td>\n      <td>12.895</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Xception w GlobalAvgPooling &amp; width shift</td>\n      <td>1.490</td>\n      <td>0.549</td>\n      <td>534.560</td>\n      <td>2.064</td>\n      <td>0.367</td>\n      <td>2.045</td>\n      <td>0.403</td>\n      <td>12.887</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>InceptionV3 w GlobalAvgPooling &amp; width shift</td>\n      <td>1.426</td>\n      <td>0.551</td>\n      <td>281.818</td>\n      <td>2.184</td>\n      <td>0.398</td>\n      <td>2.146</td>\n      <td>0.378</td>\n      <td>6.976</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brightness shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 512 validated image filenames belonging to 20 classes.\n"
    }
   ],
   "source": [
    "# Add some rotation and adjustments to images\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    #validation_split = 0.2, # set validation set to 0.2\n",
    "    #featurewise_center= True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=90,\n",
    "    #height_shift_range=[-0.08, 0.08],\n",
    "    #width_shift_range=[-0.08,0.08],\n",
    "    brightness_range=[0.90, 1.1]\n",
    ")\n",
    "\n",
    "train_generator  = train_datagen.flow_from_dataframe(\n",
    "    dataframe = sm_train_df,\n",
    "    directory = train_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    subset='training',\n",
    "    x_col='filename',\n",
    "    y_col='sirna',\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle = True,\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InceptionV3 with GlobalAvgPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(include_top=False,\n",
    "                    weights = 'imagenet',\n",
    "                    input_shape=(img_height, img_width, 3))\n",
    "\n",
    "pooling = GlobalAveragePooling2D()\n",
    "flat = Flatten()\n",
    "output = Dense(20, activation='softmax')\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    pooling,\n",
    "    flat,\n",
    "    output\n",
    "])\n",
    "\n",
    "model_name = 'InceptionV3 w GlobalAvgPooling & brightness shift'\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n16/16 [==============================] - 14s 852ms/step - loss: 3.1777 - accuracy: 0.0996 - val_loss: 3.0001 - val_accuracy: 0.0859\nEpoch 2/20\n16/16 [==============================] - 13s 816ms/step - loss: 2.5811 - accuracy: 0.2070 - val_loss: 2.7083 - val_accuracy: 0.1562\nEpoch 3/20\n16/16 [==============================] - 13s 819ms/step - loss: 2.2396 - accuracy: 0.3262 - val_loss: 2.4528 - val_accuracy: 0.2656\nEpoch 4/20\n16/16 [==============================] - 13s 796ms/step - loss: 2.0562 - accuracy: 0.3828 - val_loss: 2.3616 - val_accuracy: 0.2812\nEpoch 5/20\n16/16 [==============================] - 13s 836ms/step - loss: 2.0249 - accuracy: 0.3691 - val_loss: 2.2818 - val_accuracy: 0.3203\nEpoch 6/20\n16/16 [==============================] - 13s 798ms/step - loss: 1.8454 - accuracy: 0.4512 - val_loss: 2.2752 - val_accuracy: 0.3047\nEpoch 7/20\n16/16 [==============================] - 13s 803ms/step - loss: 1.8409 - accuracy: 0.4531 - val_loss: 2.2335 - val_accuracy: 0.3281\nEpoch 8/20\n16/16 [==============================] - 14s 851ms/step - loss: 1.6828 - accuracy: 0.4746 - val_loss: 2.1423 - val_accuracy: 0.3594\nEpoch 9/20\n16/16 [==============================] - 13s 817ms/step - loss: 1.6594 - accuracy: 0.4844 - val_loss: 2.0363 - val_accuracy: 0.3906\nEpoch 10/20\n16/16 [==============================] - 13s 800ms/step - loss: 1.5873 - accuracy: 0.5000 - val_loss: 2.1470 - val_accuracy: 0.3672\nEpoch 11/20\n16/16 [==============================] - 13s 831ms/step - loss: 1.5859 - accuracy: 0.5020 - val_loss: 2.1563 - val_accuracy: 0.3672\nEpoch 12/20\n16/16 [==============================] - 13s 808ms/step - loss: 1.5230 - accuracy: 0.5332 - val_loss: 2.0483 - val_accuracy: 0.3906\nEpoch 13/20\n16/16 [==============================] - 13s 821ms/step - loss: 1.4702 - accuracy: 0.5332 - val_loss: 1.9762 - val_accuracy: 0.3984\nEpoch 14/20\n16/16 [==============================] - 13s 820ms/step - loss: 1.4470 - accuracy: 0.5547 - val_loss: 2.0499 - val_accuracy: 0.3828\nEpoch 15/20\n16/16 [==============================] - 13s 799ms/step - loss: 1.4468 - accuracy: 0.5527 - val_loss: 2.1223 - val_accuracy: 0.3906\nEpoch 16/20\n16/16 [==============================] - 13s 807ms/step - loss: 1.3581 - accuracy: 0.5703 - val_loss: 2.1057 - val_accuracy: 0.3750\nEpoch 17/20\n16/16 [==============================] - 13s 810ms/step - loss: 1.3675 - accuracy: 0.5859 - val_loss: 2.1194 - val_accuracy: 0.3828\nEpoch 18/20\n16/16 [==============================] - 13s 800ms/step - loss: 1.3846 - accuracy: 0.5703 - val_loss: 2.0734 - val_accuracy: 0.4297\nEpoch 19/20\n16/16 [==============================] - 13s 803ms/step - loss: 1.3664 - accuracy: 0.5605 - val_loss: 1.9773 - val_accuracy: 0.4375\nEpoch 20/20\n16/16 [==============================] - 13s 807ms/step - loss: 1.2780 - accuracy: 0.6055 - val_loss: 2.1590 - val_accuracy: 0.4219\n10/10 [==============================] - 6s 591ms/step - loss: 2.1787 - accuracy: 0.3688\n"
    }
   ],
   "source": [
    "opt = RMSprop(learning_rate = 0.0001, momentum = 0.9)\n",
    "train_data, history_dict = train_model(model, opt, train_generator, val_generator, model_name)\n",
    "test_data = test_model(model, test_generator)\n",
    "results.append(save_model_data(train_data, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception with GlobalAvgPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Xception(include_top= False,\n",
    "                    weights = 'imagenet',\n",
    "                    input_shape = (img_height, img_width, 3))\n",
    "\n",
    "pooling = GlobalAveragePooling2D()\n",
    "flat = Flatten()\n",
    "output = Dense(20, activation='softmax')\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    pooling,\n",
    "    flat,\n",
    "    output\n",
    "])\n",
    "\n",
    "model_name = 'Xception w GlobalAvgPooling & brightness shift'\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n16/16 [==============================] - 25s 2s/step - loss: 2.9235 - accuracy: 0.0762 - val_loss: 2.7657 - val_accuracy: 0.2031\nEpoch 2/20\n16/16 [==============================] - 24s 2s/step - loss: 2.5527 - accuracy: 0.2500 - val_loss: 2.5137 - val_accuracy: 0.3047\nEpoch 3/20\n16/16 [==============================] - 24s 2s/step - loss: 2.3161 - accuracy: 0.3301 - val_loss: 2.3460 - val_accuracy: 0.3359\nEpoch 4/20\n16/16 [==============================] - 24s 2s/step - loss: 2.1215 - accuracy: 0.3750 - val_loss: 2.2430 - val_accuracy: 0.3438\nEpoch 5/20\n16/16 [==============================] - 24s 2s/step - loss: 1.9675 - accuracy: 0.4395 - val_loss: 2.1751 - val_accuracy: 0.3516\nEpoch 6/20\n16/16 [==============================] - 25s 2s/step - loss: 1.9491 - accuracy: 0.4219 - val_loss: 2.1251 - val_accuracy: 0.3750\nEpoch 7/20\n16/16 [==============================] - 24s 2s/step - loss: 1.8563 - accuracy: 0.4688 - val_loss: 2.0843 - val_accuracy: 0.3828\nEpoch 8/20\n16/16 [==============================] - 24s 2s/step - loss: 1.7335 - accuracy: 0.5078 - val_loss: 2.0735 - val_accuracy: 0.4062\nEpoch 9/20\n16/16 [==============================] - 24s 2s/step - loss: 1.7014 - accuracy: 0.5176 - val_loss: 2.0826 - val_accuracy: 0.3828\nEpoch 10/20\n16/16 [==============================] - 24s 2s/step - loss: 1.6973 - accuracy: 0.4863 - val_loss: 2.0718 - val_accuracy: 0.3750\nEpoch 11/20\n16/16 [==============================] - 24s 2s/step - loss: 1.6848 - accuracy: 0.4961 - val_loss: 2.0272 - val_accuracy: 0.3906\nEpoch 12/20\n16/16 [==============================] - 24s 2s/step - loss: 1.5876 - accuracy: 0.5254 - val_loss: 1.9730 - val_accuracy: 0.4141\nEpoch 13/20\n16/16 [==============================] - 24s 2s/step - loss: 1.6177 - accuracy: 0.5410 - val_loss: 1.9544 - val_accuracy: 0.4062\nEpoch 14/20\n16/16 [==============================] - 24s 2s/step - loss: 1.5730 - accuracy: 0.5293 - val_loss: 1.9663 - val_accuracy: 0.4219\nEpoch 15/20\n16/16 [==============================] - 25s 2s/step - loss: 1.5418 - accuracy: 0.5293 - val_loss: 1.9663 - val_accuracy: 0.3984\nEpoch 16/20\n16/16 [==============================] - 25s 2s/step - loss: 1.5104 - accuracy: 0.5547 - val_loss: 1.9768 - val_accuracy: 0.3984\nEpoch 17/20\n16/16 [==============================] - 25s 2s/step - loss: 1.5003 - accuracy: 0.5391 - val_loss: 1.9713 - val_accuracy: 0.3984\nEpoch 18/20\n16/16 [==============================] - 25s 2s/step - loss: 1.4453 - accuracy: 0.5625 - val_loss: 1.9435 - val_accuracy: 0.4297\nEpoch 19/20\n16/16 [==============================] - 25s 2s/step - loss: 1.4643 - accuracy: 0.5547 - val_loss: 1.9717 - val_accuracy: 0.4297\nEpoch 20/20\n16/16 [==============================] - 24s 2s/step - loss: 1.3816 - accuracy: 0.6055 - val_loss: 1.9163 - val_accuracy: 0.4219\n10/10 [==============================] - 12s 1s/step - loss: 2.0170 - accuracy: 0.3844\n"
    }
   ],
   "source": [
    "opt = RMSprop(learning_rate = 0.0001, momentum = 0.9)\n",
    "train_data, history_dict = train_model(model, opt, train_generator, val_generator, model_name)\n",
    "test_data = test_model(model, test_generator)\n",
    "results.append(save_model_data(train_data, test_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit0c31753cb4904f759510df829f98c315"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}